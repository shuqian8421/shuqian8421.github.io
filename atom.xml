<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>疏堑的博客</title>
  
  <subtitle>ShuQian&#39;s Blog</subtitle>
  <link href="https://shuqian8421.github.io/atom.xml" rel="self"/>
  
  <link href="https://shuqian8421.github.io/"/>
  <updated>2025-02-12T10:38:08.581Z</updated>
  <id>https://shuqian8421.github.io/</id>
  
  <author>
    <name>疏堑</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>穷游香港之食物篇</title>
    <link href="https://shuqian8421.github.io/posts/23075/"/>
    <id>https://shuqian8421.github.io/posts/23075/</id>
    <published>2025-01-26T16:00:00.000Z</published>
    <updated>2025-02-12T10:38:08.581Z</updated>
    
    <content type="html"><![CDATA[<div class="note blue flat"><p>民以食为天，再空的钱包也阻挡不了我们探寻美食的决心。但此地餐厅别具一格的服务质量实在是令人叹惋；若想接触到些高雅的吃食更难免让钱包受灾。作为“性价比”一词的狂热追随者，我致力于分享物美价廉的美食，从正餐到零食，谨作为个人建议。</p></div><h1 id="餐厅"><a href="#餐厅" class="headerlink" title="餐厅"></a>餐厅</h1><h2 id="岱民西环店"><a href="#岱民西环店" class="headerlink" title="岱民西环店"></a>岱民西环店</h2><div class="tabs" id="head"><ul class="nav-tabs"><button type="button" class="tab  active" data-href="head-1">须知</button><button type="button" class="tab " data-href="head-2">地址</button></ul><div class="tab-contents"><div class="tab-item-content active" id="head-1"><div class="note warning flat"><p>此店不支持微信支付、不支持支付宝支付！</p></div></div><div class="tab-item-content" id="head-2"><p>西环德辅道西218号<br><a href="https://maps.app.goo.gl/6qeqScr174SjE4Lq5?g_st=ac">谷歌地图</a></p></div></div><div class="tab-to-top"><button type="button" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div><div class="note modern"><p>两送饭（HKD$28）★★★★★<br><img src="../../../img/posts/PoorTourHongKongFood/DMXHD_LSF.jpg", width=400px><br>物美价廉呐（赞赏）！</p></div><h2 id="香港大学庄月明餐厅"><a href="#香港大学庄月明餐厅" class="headerlink" title="香港大学庄月明餐厅"></a>香港大学庄月明餐厅</h2><div class="tabs" id="head"><ul class="nav-tabs"><button type="button" class="tab  active" data-href="head-1">须知</button><button type="button" class="tab " data-href="head-2">地址</button><button type="button" class="tab " data-href="head-3">线上点餐</button></ul><div class="tab-contents"><div class="tab-item-content active" id="head-1"><div class="note warning flat"><p>大多数情况下你需要香港大学学生卡或者登录HKU App才能进入香港大学并点餐。</p></div><div class="note info flat"><p>参考菜单详见<a href="https://www.cedars.hku.hk/catering/menu/CYMACRMenu.pdf">此处</a>。随着时间和季节的变化，菜单可能也会变化。</p></div></div><div class="tab-item-content" id="head-2"><p>薄扶林香港大學莊月明文娛中心4樓<br>4/F, Chong Yuet Ming Amenities Centre, University of Hong Kong, Pok Fu Lam</p><p>港鐵香港大學站 A1 出口, 步行約6分鐘</p></div><div class="tab-item-content" id="head-3"><div class="note info flat"><p>你可以通过下面这个二维码或访问<a href="https://scan.aigens.com/scan?code=c3RvcmU9MTAyODU4Jm1vZGU9cHJla2lvc2smcGFnZT1ieW9k">香港大学庄月明餐厅点餐链接</a>进行线上点餐，当然你同样得有香港大学学生卡或者HKU App。</p><div class="img-wrap"><div class="img-bg"><img class="img" src="../../../img/posts/PoorTourHongKongFood/CYM.png" style="width:200px;"/></div></div></div></div></div><div class="tab-to-top"><button type="button" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div><p>推荐以下菜品</p><div class="note modern"><p>烧味双拼饭（HKD$28.8）★★★★★<br><img src="../../../img/posts/PoorTourHongKongFood/HKUCYM_SWSPF.jpg", width=400px><br>物美价廉啊（赞赏）！</p></div><div class="note modern"><p>冻鸳鸯（HKD$8.7）★★★★★<br><img src="../../../img/posts/PoorTourHongKongFood/HKUCYM_DYY.jpg", width=400px><br>香港饮料唯一真神。茶+咖啡+炼乳，早上喝一杯，整天都精神！单买比较贵，最好含饮料的套餐内加2.7港币转冻饮，更划算。</p></div><div class="note modern"><p>仿鲍丝火腿汤通粉套餐（HKD$25.2）★★★☆☆<br><img src="../../../img/posts/PoorTourHongKongFood/HKUCYM_FBSHTTTFTC.jpg", width=400px></p><p><div class="note info flat"><p>仅在早餐供应</p></div></p><p><p>半圆形意大利面（macaroni）加上一些火腿碎，难得的有肉汤味。套餐内有赠一杯热饮。<br></p></div></p><div class="note modern"><p>紫菜豆腐脆肉鱼片汤饭（HKD$49）★★★☆☆<br><img src="../../../img/posts/PoorTourHongKongFood/HKUCYM_ZCDFCRYPTF.jpg", width=400px><br>滋味不错，量有点太多，吃到最后发现剩了好多蘑菇。汤味道浓郁，鱼肉软嫩。</p></div><h2 id="香港大学Union-Restaurant"><a href="#香港大学Union-Restaurant" class="headerlink" title="香港大学Union Restaurant"></a>香港大学Union Restaurant</h2><div class="tabs" id="head"><ul class="nav-tabs"><button type="button" class="tab  active" data-href="head-1">须知</button><button type="button" class="tab " data-href="head-2">地址</button><button type="button" class="tab " data-href="head-3">线上点餐</button></ul><div class="tab-contents"><div class="tab-item-content active" id="head-1"><div class="note warning flat"><p>大多数情况下你需要香港大学学生卡或者登录HKU App才能进入香港大学并点餐。</p></div><div class="note info flat"><p>参考菜单详见<a href="https://www.cedars.hku.hk/catering/menu/URMenu.pdf">此处</a>。随着时间和季节的变化，菜单可能也会变化。</p></div></div><div class="tab-item-content" id="head-2"><p>4/F, Haking Wong Building, Pok Fu Lam Rd, Lung Fu Shan</p><p>港鐵香港大學站 A1 出口, 步行約6分鐘</p></div><div class="tab-item-content" id="head-3"><div class="note info flat"><p>你可以通过下面这个二维码或访问<a href="https://now.order.place/#/store/12827/mode/prekiosk">香港大学Union Restaurant点餐链接</a>进行线上点餐，当然你同样得有香港大学学生卡或者HKU App。</p><div class="img-wrap"><div class="img-bg"><img class="img" src="../../../img/posts/PoorTourHongKongFood/UnionRestaurant.png" style="width:200px;"/></div></div></div></div></div><div class="tab-to-top"><button type="button" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div><p>推荐以下菜品</p><div class="note modern"><p>仿鲍丝火腿汤通粉套餐（HKD$33.6）★★★★☆<br><img src="../../../img/posts/PoorTourHongKongFood/UnionRestaurant_FBSLXNTTF.jpg", width=400px></p><p><div class="note info flat"><p>仅在早餐供应</p></div></p><p><p>半圆形意大利面（macaroni）加上一些菇条，汤好喝。套餐内有赠一杯热饮。虽然小贵，但值得。<br></p></div></p><div class="note modern"><p>皮蛋瘦肉粥·豉油皇炒面（HKD$20.5）★★★★★<br><img src="../../../img/posts/PoorTourHongKongFood/UnionRestaurant_PDSRZ.jpg", width=400px></p><p><div class="note info flat"><p>仅在早餐供应</p></div></p><p><p>物美价廉呐（赞赏）！虽然粥米粒碎碎的不过有的吃就不错了。炒面没啥味道但主打一个管饱，吃完后嘴可能会有些干，最好备些水。<br></p></div></p><div class="note modern"><p>麻辣鸡煲（HKD$49.8）★★★★☆<br><img src="../../../img/posts/PoorTourHongKongFood/UnionRestaurant_MLJB.jpg", width=400px><br>味道完美，芡汁都能挂住，可惜有点太贵了。</p></div><h2 id="香港大学方树泉文娱中心餐厅"><a href="#香港大学方树泉文娱中心餐厅" class="headerlink" title="香港大学方树泉文娱中心餐厅"></a>香港大学方树泉文娱中心餐厅</h2><div class="tabs" id="head"><ul class="nav-tabs"><button type="button" class="tab  active" data-href="head-1">须知</button><button type="button" class="tab " data-href="head-2">地址</button></ul><div class="tab-contents"><div class="tab-item-content active" id="head-1"><div class="note warning flat"><p>大多数情况下你需要香港大学学生卡或者登录HKU App才能进入香港大学并点餐。</p></div><div class="note info flat"><p>参考菜单详见<a href="https://www.cedars.hku.hk/catering/menu/FSCACRMenu.pdf">此处</a>。随着时间和季节的变化，菜单可能也会变化。</p></div></div><div class="tab-item-content" id="head-2"><p>2/F, Fong Shu Chuen Amenities Centre</p><p>港鐵香港大學站 A1 出口, 步行約6分鐘</p></div></div><div class="tab-to-top"><button type="button" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div><p>推荐以下菜品</p><div class="note modern"><p>水煮牛肉（HKD$39）★★★★★<br><img src="../../../img/posts/PoorTourHongKongFood/FSCAC_SZNR.jpg", width=400px><br>很实惠啊！有点小辣，最好备些水。</p></div><div class="note modern"><p>冻鸳鸯（HKD$6.5）★★★★★<br><img src="../../../img/posts/PoorTourHongKongFood/FSCAC_DYY.jpg", width=400px><br>香港饮料唯一真神。茶+咖啡+炼乳，早上喝一杯，整天都精神！单买比较贵，最好含饮料的套餐内加2.7港币转冻饮，更划算。</p></div><div class="note modern"><p>麻婆豆腐饭（HKD$24）★★★★☆<br><img src="../../../img/posts/PoorTourHongKongFood/FSCAC_MPDFF.jpg", width=400px><br>便宜，可惜量有点小。</p></div><h1 id="食材"><a href="#食材" class="headerlink" title="食材"></a>食材</h1><h2 id="意大利面"><a href="#意大利面" class="headerlink" title="意大利面"></a>意大利面</h2><div class="table-container"><table><thead><tr><th style="text-align:center">地点</th><th style="text-align:center">单价（HKD）</th><th style="text-align:center">商品名称及图片</th><th style="text-align:center">评价</th></tr></thead><tbody><tr><td style="text-align:center"><kbd>佳宝食品超级市场</kbd> <a href="https://maps.app.goo.gl/EDoPTUsyu2s9CY5Q9?g_st=ac">谷歌地图</a><br>香港堅尼地城堅彌地城海旁6-8號地下E,F及G地舖</td><td style="text-align:center"><del>10.5</del> 6.45</td><td style="text-align:center"><div class="img-wrap"><div class="img-bg"><img class="img" src="../../../img/posts/PoorTourHongKongFood/PastaRicco.jpg" alt="1017627-Pasta Ricco意大利粉500g" style="width:400px;"/></div><span class="image-caption">1017627-Pasta Ricco意大利粉500g</span></div></td><td style="text-align:center">买两个有折扣</td></tr></tbody></table></div><h2 id="意粉酱"><a href="#意粉酱" class="headerlink" title="意粉酱"></a>意粉酱</h2><div class="table-container"><table><thead><tr><th style="text-align:center">地点</th><th style="text-align:center">单价（HKD）</th><th style="text-align:center">商品名称及图片</th><th style="text-align:center">评价</th></tr></thead><tbody><tr><td style="text-align:center"><kbd>佳宝食品超级市场</kbd> <a href="https://maps.app.goo.gl/EDoPTUsyu2s9CY5Q9?g_st=ac">谷歌地图</a><br>香港堅尼地城堅彌地城海旁6-8號地下E,F及G地舖</td><td style="text-align:center"><del>16.9</del> 14.5</td><td style="text-align:center"><div class="img-wrap"><div class="img-bg"><img class="img" src="../../../img/posts/PoorTourHongKongFood/PastaJiang.jpg" alt="1000718-金宝卡邦尼蘑菇意粉酱295g" style="width:400px;"/></div><span class="image-caption">1000718-金宝卡邦尼蘑菇意粉酱295g</span></div></td><td style="text-align:center">买两个有折扣，味道略显寡淡</td></tr></tbody></table></div><h1 id="零食"><a href="#零食" class="headerlink" title="零食"></a>零食</h1><h2 id="牛奶"><a href="#牛奶" class="headerlink" title="牛奶"></a>牛奶</h2><div class="table-container"><table><thead><tr><th style="text-align:center">地点</th><th style="text-align:center">单价（HKD）</th><th style="text-align:center">商品名称及图片</th><th style="text-align:center">评价</th></tr></thead><tbody><tr><td style="text-align:center"><kbd>佳宝食品超级市场</kbd> <a href="https://maps.app.goo.gl/EDoPTUsyu2s9CY5Q9?g_st=ac">谷歌地图</a><br>香港堅尼地城堅彌地城海旁6-8號地下E,F及G地舖</td><td style="text-align:center"><del>14.9</del> 12</td><td style="text-align:center"><div class="img-wrap"><div class="img-bg"><img class="img" src="../../../img/posts/PoorTourHongKongFood/DanaMilk.jpg" alt="1017124-DANA全脂牛奶（纸盒）1L" style="width:400px;"/></div><span class="image-caption">1017124-DANA全脂牛奶（纸盒）1L</span></div></td><td style="text-align:center">买两个有折扣，又便宜又好喝（乳糖不耐受用户请谨慎饮用，可能导致呕吐）</td></tr></tbody></table></div><h2 id="开心果"><a href="#开心果" class="headerlink" title="开心果"></a>开心果</h2><div class="table-container"><table><thead><tr><th style="text-align:center">地点</th><th style="text-align:center">单价（HKD）</th><th style="text-align:center">商品名称及图片</th><th style="text-align:center">评价</th></tr></thead><tbody><tr><td style="text-align:center"><kbd>佳宝食品超级市场</kbd> <a href="https://maps.app.goo.gl/EDoPTUsyu2s9CY5Q9?g_st=ac">谷歌地图</a><br>香港堅尼地城堅彌地城海旁6-8號地下E,F及G地舖</td><td style="text-align:center"><del>55</del> 49</td><td style="text-align:center"><div class="img-wrap"><div class="img-bg"><img class="img" src="../../../img/posts/PoorTourHongKongFood/HappyFruit.jpg" alt="1013365-Andi 开心果380g" style="width:400px;"/></div><span class="image-caption">1013365-Andi 开心果380g</span></div></td><td style="text-align:center">买两个有折扣，味道不错</td></tr></tbody></table></div><h2 id="速溶咖啡"><a href="#速溶咖啡" class="headerlink" title="速溶咖啡"></a>速溶咖啡</h2><div class="table-container"><table><thead><tr><th style="text-align:center">地点</th><th style="text-align:center">单价（HKD）</th><th style="text-align:center">商品名称及图片</th><th style="text-align:center">评价</th></tr></thead><tbody><tr><td style="text-align:center"><kbd>佳宝食品超级市场</kbd> <a href="https://maps.app.goo.gl/EDoPTUsyu2s9CY5Q9?g_st=ac">谷歌地图</a><br>香港堅尼地城堅彌地城海旁6-8號地下E,F及G地舖</td><td style="text-align:center">29.9</td><td style="text-align:center"><div class="img-wrap"><div class="img-bg"><img class="img" src="../../../img/posts/PoorTourHongKongFood/OldTownWhiteCoffee.jpg" alt="1001089-旧街场3合1白咖啡减糖分350g" style="width:400px;"/></div><span class="image-caption">1001089-旧街场3合1白咖啡减糖分350g</span></div></td><td style="text-align:center">原味浓郁较甜，推荐此款-30%糖度的</td></tr></tbody></table></div><h2 id="速溶奶茶"><a href="#速溶奶茶" class="headerlink" title="速溶奶茶"></a>速溶奶茶</h2><div class="table-container"><table><thead><tr><th style="text-align:center">地点</th><th style="text-align:center">单价（HKD）</th><th style="text-align:center">商品名称及图片</th><th style="text-align:center">评价</th></tr></thead><tbody><tr><td style="text-align:center"><kbd>百佳超级市场</kbd> <a href="https://maps.app.goo.gl/x2vxoCBKrwbTgMJFA?g_st=ac">谷歌地图</a><br>地下 G/F, Cheung Fat Industrial Building, 香港石塘咀山道7-9號, 7-9 Hill Rd, Shek Tong Tsui, 香港</td><td style="text-align:center"><del>24.5</del> 19.5</td><td style="text-align:center"><div class="img-wrap"><div class="img-bg"><img class="img" src="../../../img/posts/PoorTourHongKongFood/MrBrownMilkTea.jpg" alt="322058 伯朗奶茶三合一" style="width:400px;"/></div><span class="image-caption">322058 伯朗奶茶三合一</span></div></td><td style="text-align:center">买两个有折扣，量大管饱</td></tr></tbody></table></div>]]></content>
    
    
    <summary type="html">吃着两送饭的博主，想到星光大道那金碧辉煌的维多利亚港时，不由得挺起了胸膛</summary>
    
    
    
    <category term="穷游香港" scheme="https://shuqian8421.github.io/categories/%E7%A9%B7%E6%B8%B8%E9%A6%99%E6%B8%AF/"/>
    
    
    <category term="香港" scheme="https://shuqian8421.github.io/tags/%E9%A6%99%E6%B8%AF/"/>
    
  </entry>
  
  <entry>
    <title>数据可视化笔记</title>
    <link href="https://shuqian8421.github.io/posts/28613/"/>
    <id>https://shuqian8421.github.io/posts/28613/</id>
    <published>2024-09-24T16:00:00.000Z</published>
    <updated>2025-02-12T10:38:08.580Z</updated>
    
    <content type="html"><![CDATA[<h2 id="绪论"><a href="#绪论" class="headerlink" title="绪论"></a>绪论</h2><ol><li>什么是可视化：利用人眼的感知能力对数据进行交互的可视表达以增强认知的技术</li><li>可视化的作用<ul><li>记录信息</li><li>分析推理</li><li>证实假设</li><li>交流思想<br>变化盲视：当我们同时经历着多样事物发生时仅仅 关注其中一样而忽视了其他样事物的发生而且不知道它们的发生，我们称这种 现象为变化盲视。</li></ul></li><li>总结：可视化<ul><li>协助思考</li><li>使用感知代替认知</li><li>作为大量工作记忆的外界辅助</li><li>增强认知能力</li></ul></li></ol><h2 id="视觉感知与认知"><a href="#视觉感知与认知" class="headerlink" title="视觉感知与认知"></a>视觉感知与认知</h2><h3 id="视觉感知与认知-1"><a href="#视觉感知与认知-1" class="headerlink" title="视觉感知与认知"></a>视觉感知与认知</h3><ol><li>什么是感知：是指客观事物通过人的感觉器官在人脑 中形成的直接反映</li><li>视觉感知可分为两个阶段：<ul><li>受到外部刺激接收信息阶段</li><li>解释信息阶段</li></ul></li><li>视觉感知特点<ul><li>一方面，眼睛和视觉系统的物理特性决定了人类无法看到某些事物；</li><li>另一方面，视觉系统进行解释处理信息时可对不完全信息发挥一定的想象力。进行人机交互设计需要清楚这两个阶段及其影响，了解人类真正能够看到的信息。</li></ul></li><li>什么是认知：认知心理学将认知过程看成由信息的获取、分析、归纳、解码、储存、概念形成、提取和使用等一系列阶段组 成的按一定程序进行的信息加工过程。</li><li>格式塔理论<ol><li>最基本的法则是简单贴近法则<ul><li>人们在进行观察的时候，倾向于将视觉感知内容理解为常规的、简单的、相连的、 对称的或有序的结构</li><li>同时，人们在获取视觉感知的时候，会倾向于将事物理解为一个整体，而不是将 事物理解为组成该事物所有部分的集合</li></ul></li><li>格式塔法则又称为完图法则，主要包括<ul><li>贴近法则：当视觉元素(即一些被人识别的视觉感知对象)在空间距离上相距较近时，人们通常倾向于将它们归为一组</li><li>相似原则：人们在观察事物的时候，会自然地根据事物的相似性进行感知分组。通常依据对形状、颜色、光照或其他性质的感知进行分组</li><li>连续原则：人们在观察事物的时候会很自然地沿着物体的边界，将不连续的物体视为连续的整体</li><li>闭合原则：只要物体的形状足以表征物体本身，人们就会很容易地感知整个物体而忽视未闭合的特征</li><li>共势原则：如一组物体具有沿着相似的光滑路径运动趋势或相似的排列模式，人眼会将它们识别为同一类物体</li><li>好图原则：人眼通常会自动将一组物体按照简单、规则、有序的元素排列方式进行识别。个体识别世界的时候通常会消除复杂性和不熟悉性，并采纳最简化的形式</li><li>对称性原则：人的意识倾向于将物体识别为沿某点或某轴对称的形状。因此，将数据按照对称性原则分为偶数个对称的部分，对称的部分会被下意识地识别为相连的形状，从而增强认知的愉悦度</li><li>经验原则：在某些情形下视觉感知与过去的经验有关。如果两个物体看上去距离相近，或者时间间隔小，那么它们通常被识别为同一类</li></ul></li></ol></li></ol><h3 id="色彩"><a href="#色彩" class="headerlink" title="色彩"></a>色彩</h3><ol><li>色彩的物理学基础<br>加性混合主要应用于主动发光的物体，减性混合主要应用于被动发光的物体。</li><li>视网膜三类细胞：杆状细胞、锥状细胞、神经节细胞。</li><li>脑神经感知颜色的几个特性<ul><li>颜色恒定性</li><li>人脑对颜色的感知取决于该颜色与周围颜色的关系</li><li>人脑对亮度变化的感知要比色相变化的感知敏感</li></ul></li><li>加色法系统RGB、减色法系统CMYK</li><li>HSV/HSL色彩空间<ol><li>HSL：<ul><li>色相（Hue）：人类认为的颜色</li><li>饱和度（Saturation）：纯度，与灰色的距离</li><li>亮度（Lightness）：从黑色到亮色</li></ul></li><li>HSV：<ul><li>色相（Hue）：人类认为的颜色</li><li>饱和度（Saturation）：纯度，与灰色的距离</li><li>明度（Value）：从黑色到亮色</li></ul></li></ol></li><li>绝对色彩空间与相对色彩空间<br>绝对色彩空间是指不依赖于外部因素就可以准确地表 示颜色的色彩空间，相对色彩空间无法通过一组值准确地表示颜色，相同的值未必能使人得到相同的色彩感知。</li></ol><h3 id="视觉编码原则"><a href="#视觉编码原则" class="headerlink" title="视觉编码原则"></a>视觉编码原则</h3><ol><li>视觉假象<br>人们通过眼睛所获得的信息被大脑处理后形成的关于事物的感知，与事物在客观世界中的物理现实并不一致，这种现象称为视觉假象<ul><li>尺寸错觉（深度错觉）：是指人们根据深度线索或 环境信息等视觉规则对相同面积，长度和体积的物 体得出不同认知的现象。</li><li>细胞错觉：指因视觉神经上功能相似的神经元群或神经组织作用 对刺激的亮度、颜色、方向模式产生误解的现象，包过视觉后象、 侧抑制、填充视觉产生的一些错觉现象</li><li>轮廓错觉：专指人和动物对图像边缘梯度信息和环境 认知出现错误的现象，包括知觉迷糊，背景错觉等。</li><li>不可能错觉：局部平面结构理解合理却不能客观存在的图形。如： 不可能梯形、不可能三角形等。</li><li>运动错觉：指人结合环境线索对运动刺激判断出错误方向，或者 把静态的感知到运动的状态的错觉。如循环蛇，辐条错觉等。</li></ul></li><li>数据通常包含了属性和值，可视化编码包括：标记(图形元素)和用于控制标 记的视觉特征的视觉通道</li></ol><ul><li>标记通常是一些几何图形元素；标记具有分类性质，因此不同的标记可用于 编码不同的数据属性</li><li>视觉通道则用于控制标记的展现特征，从定量的角度描述标记在可视化图像中的呈现状态</li></ul><h2 id="数据基础"><a href="#数据基础" class="headerlink" title="数据基础"></a>数据基础</h2><h3 id="数据基础-1"><a href="#数据基础-1" class="headerlink" title="数据基础"></a>数据基础</h3><ol><li>数据属性：数据对象的特征或特性<br>属性集合：属性向量</li></ol><h3 id="数据特征"><a href="#数据特征" class="headerlink" title="数据特征"></a>数据特征</h3><ol><li>均值、中位数、均方差</li><li>Jaccard相似性系数，用来比较样本集种的相似性和分散性的一个概率。<script type="math/tex">d(i,j)=\frac{r+s}{q+r+s}</script></li><li>明科夫斯基距离系</li></ol><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><ol><li>ETL：抽取、转化、装载<br>ETL负责将分散的、异构数据源中的数据如关系数据、平面数据文件等抽取 到临时中间层后进行清洗、转换、集成，最后加载到数据仓库或数据集市中，成 为联机分析处理、数据挖掘的基础。</li><li>数据质量<ul><li>精确性</li><li>完整性</li><li>一致性</li><li>适时性</li><li>可信性</li><li>可解释性</li></ul></li><li>数据错误类型及处理方法<ol><li>缺失值<ul><li>常量代替缺失值</li><li>属性平均值填充</li><li>插值</li><li>忽略</li><li>回归</li><li>人工填充</li></ul></li><li>噪声值<ul><li>回归分析</li><li>离群点分析</li></ul></li><li>数据重复</li></ol></li></ol><h3 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h3><ol><li>探索式数据分析EDA中的可视化方法分类：<ul><li>原始数据绘图</li><li>简单统计值标绘</li><li>多视图协调关联</li></ul></li></ol><h2 id="数据可视化基础"><a href="#数据可视化基础" class="headerlink" title="数据可视化基础"></a>数据可视化基础</h2><h3 id="数据可视化流程"><a href="#数据可视化流程" class="headerlink" title="数据可视化流程"></a>数据可视化流程</h3><ol><li>数据可视化流程以数据流为主线，包括数据采集、数据处理和变换、可视化映射、 用户感知</li><li>可视化流程三个核心要素<ul><li>数据表示与变换</li><li>数据可视化呈现</li><li>用户交互</li></ul></li></ol><h2 id="统计图可视化"><a href="#统计图可视化" class="headerlink" title="统计图可视化"></a>统计图可视化</h2><h3 id="数据变换"><a href="#数据变换" class="headerlink" title="数据变换"></a>数据变换</h3><ol><li>简单的变换<ul><li>线性变换</li><li>对数变换</li><li>反正切变换</li></ul></li><li>常用的典型数据变换<ul><li>标准化</li><li>拟合/平滑</li><li>采样</li><li>降维</li><li>聚类</li></ul></li><li>K-means<ul><li>随机产生K个中心位置</li><li>将每个数据点归为距离最近的中心位置所属的类</li><li>根据新的类别划分重新计算中心位置</li><li>回到第二步，直到满足一定约束</li></ul></li><li>K-medoids<ul><li>中心位置必须在数据点所在位置上</li><li>中心位置满足“到类内所有数据点的距离之和最小”</li><li>因而可以处理“距离型”数据</li></ul></li></ol><h3 id="常用图表工具"><a href="#常用图表工具" class="headerlink" title="常用图表工具"></a>常用图表工具</h3><ul><li>Tableau</li><li>Echarts</li><li>Highcharts</li></ul><h2 id="地理数据可视化"><a href="#地理数据可视化" class="headerlink" title="地理数据可视化"></a>地理数据可视化</h2><h3 id="地图的投影"><a href="#地图的投影" class="headerlink" title="地图的投影"></a>地图的投影</h3><ol><li>按照曲面映射过程中的的优化目标区分，地图映射主要包含以下三种类型<ul><li>等距离：即投影后任何点到原点的距离保持不变<ol><li>方位角等距离投影。地图上任何一点沿着经度线到投影中原点的距离保持不变</li></ol></li><li>等面积：地图上任何图形面积经主比例尺放大以后与实地上相应图形面积大小保持不变<ol><li>正弦曲线等面积伪圆柱投影。一种等面积投影，在经纬度投影的基础上对经线加以扭曲以满足等面积特性。</li><li>Lambert 等面积方位角投影。假定球面与平面切于一点，按等积条件将经纬线投影于平面。比起经纬度投影，高纬度段被“压扁”以实现等面积投影。</li><li>亚尔勃斯投影：保持面积不变的正轴等面积割圆锥投影。</li></ol></li><li>等角度：源曲面和目标曲面（即投影前后）的任何位置的两个微分线段组成的角度投影前后保持不变<ol><li>墨卡托投影：一种圆柱等角投影</li><li>Lambert圆锥等角投影。用一个正圆锥切于或割于球面，应用等角条件将地球面投影到圆锥面上，之后展开圆锥。</li></ol></li></ul></li></ol><h3 id="点数据可视化"><a href="#点数据可视化" class="headerlink" title="点数据可视化"></a>点数据可视化</h3><ol><li>点数据描述的对象是地理空间中离散的点，具有经度和纬度的坐标，但不具备大小尺寸。最直接可视化点数据的方法是将对象根据它的坐标直接标识在地图上，圆点是最常用的标识符号。</li><li>以点数据描述离散的地点<ul><li>优点：简单，直观，与逻辑结构相匹配</li><li>缺点：对于密集数据点表述力差</li></ul></li></ol><h3 id="线数据可视化"><a href="#线数据可视化" class="headerlink" title="线数据可视化"></a>线数据可视化</h3><ol><li>线数据通常指的连接两个或更多地点的线段或者路径。线数据具有长度属性，即所经过的地理距离。</li><li>FlowMap算法<ol><li>Layout Adjustment<ul><li>将地图上的节点映射到屏幕上(km-&gt;pixel)</li><li>调整节点布局以避免节点间的相互干扰。</li><li>布局调整应当<ul><li>保持节点间的x, y顺序（以保证相对稳定的位置关系）</li><li>对于每一组节点u, v，在x, y方向上满足u, v间距离不小于<script type="math/tex">k_{uv}</script>。</li><li>在x, y方向对所有节点进行排序后通过一组线性扫描可以在<script type="math/tex">O(n^2)</script>内满足约束。</li></ul></li></ul></li><li>Primary Clustering<ul><li>将所有节点依位置关系聚类</li><li>聚类方法<ul><li>对所有数据点对&lt;u,v&gt;，计算u,v之间的欧氏距离</li><li>将距离最近的点对合并，依data flow值加权取重心作为一个新的数据点，并计算其与所有原有节点间的欧氏距离。新节点的权值是合并的两节点权值(data flow)之和。并对新节点建立包围盒。</li><li>重复上述操作直至只有一个数据点为止，我们即可形成一个二叉树状的聚类结构。</li></ul></li></ul></li><li>Rooted Clustering<ul><li>在聚类结果中考虑源\汇(Source\Terminal)，并将其移动至根节点</li><li>对于二叉树中的每一个节点，选择其中权值较高的子节点，直接连接父节点a与该子节点的重心c交子节点的包围盒于b。取ab中点引出权值较低的子节点。</li></ul></li><li>Edge Routing<ul><li>上述操作并不保证边与边之间不相交——显然地，如果边与边（流与流）之间相交会引发图中较大的混乱，因此我们需要令这些边互相绕开</li></ul></li></ol></li></ol><h2 id="时空数据可视化"><a href="#时空数据可视化" class="headerlink" title="时空数据可视化"></a>时空数据可视化</h2><h3 id="空间数据"><a href="#空间数据" class="headerlink" title="空间数据"></a>空间数据</h3><ol><li>空间数据指带有物理空间坐标的数据（空间场数据）</li><li>数据从哪里来<ul><li>实测数据：数据从传感器来。数据网格由传感器的排布决定</li><li>仿真数据：数据从模拟运算来。数据网格由仿真粒度决定。</li></ul></li><li>空间网格形式<ul><li>按照三位数据场的采样组织方式划分，分为：有网格和无网格。</li><li>按照网格形态划分，分为：均匀网格、矩形网格、曲线网格、不规则网格。</li></ul></li></ol><h3 id="一维数据可视化"><a href="#一维数据可视化" class="headerlink" title="一维数据可视化"></a>一维数据可视化</h3><ol><li>多属性时，可以采用不同的可视化方法表达多值域数据。</li><li>如果值域数据具有相同的物理属性，不同颜色和线条在同一个图中对比</li><li>如果值域数据的物理属性不同，多个子图的形式来可视化不同的属性</li></ol><h3 id="二维数据可视化"><a href="#二维数据可视化" class="headerlink" title="二维数据可视化"></a>二维数据可视化</h3><ol><li>颜色映射法<ul><li>步骤<ul><li>建立颜色映射表</li><li>将标量数据转换为颜色表的索引值</li><li>选择配色方案：ColorBrewer</li></ul></li><li>关键：颜色映射，即传输函数设计</li><li>本质上即为将一个标量值映射到一种颜色</li></ul></li><li>等值线映射法<ul><li>等值线是可视化二维空间标量场的基本方法</li><li>计算：假设f(x, y)是在点(x, y)处的数值，等值线是在多维空间标量场中满足f(x, y) = c的空间点集按一定顺序连接而成的线</li><li>移动四边形法：逐个处理二维空间标量场的网格单元，插值计算等值线与该网格单元边的交点，根据网格单元上每个顶点与等值线的相对位置，按一定顺序连接这些交点，生成等值线</li></ul></li><li>高度映射法</li></ol><h3 id="三维数据可视化"><a href="#三维数据可视化" class="headerlink" title="三维数据可视化"></a>三维数据可视化</h3><ol><li>三维数据场是指分布在三维物理空间，记录三维空间场的物理化学等属性及其演化规律的数据场</li><li>获取方式分为两类：设备采集获取和计算模拟</li><li>三维数据场本质是一个对连续信号采样形成的离散数据场，采样点数据类型分为<ul><li>标量</li><li>矢量</li><li>向量</li></ul></li><li>三维数据体绘制<ul><li>截面可视化</li><li>间接体绘制<ul><li>等值面提取与绘制</li></ul></li><li>直接体绘制<ul><li>图像空间方法<ul><li>光线投射算法：对于图像平面上的每一像素，从视点投射出一穿过该像素的视线，该视线穿过体数据空间，算法直接利用该视线上的采样值合成该像素的颜色值。</li></ul></li><li>数据空间方法</li><li>传输函数设计</li></ul></li></ul></li></ol><h2 id="时空数据可视化——向量张量可视化"><a href="#时空数据可视化——向量张量可视化" class="headerlink" title="时空数据可视化——向量张量可视化"></a>时空数据可视化——向量张量可视化</h2><h3 id="向量数据可视化"><a href="#向量数据可视化" class="headerlink" title="向量数据可视化"></a>向量数据可视化</h3><ol><li>向量场数据可视化方法<ul><li>基于标量场映射可视化：将向量数据转化为标量，充分利用比较成熟的标量可视化技术。</li><li>基于几何的方法<ul><li>标记法：线条、箭头、方向标志符（三角图符）等，类似与传统物理学中用碎铁屑展示磁力线的方法。优点：实现简单、直观、灵活。缺点：在三维空间下会显得非常杂乱。</li><li>基于积分曲线的方法<ul><li>用来可视化流体的四种线<ul><li>流线（ streamline ）是沿着流体速度矢量的瞬间切线方向的一组曲线。它们显示了流体质点在任何时间点上的运动方向。</li><li>迹线（ pathline ）是一个流体颗粒的运动轨迹。它们可以被理解为流体质子在一定时间内运动路线的“记录”。路线的方向取决于时间内的每一个时刻上流体的流线。</li><li>烟线（也称脉线 ，streakline ）是经过某个特定的空间点上所有流体颗粒的点的轨迹。染料逐渐通过一个固定的点注入流体，就延伸为一条烟线。</li><li>时线（ timeline ）是由一组在时间内同一个瞬间被标记的一组流体颗粒形成的线，所创建的直线或曲线由于颗粒随时间推移运动而发生位移。</li></ul></li></ul></li></ul></li><li>基于纹理的方法<ul><li>点噪音：随机排列一些圆点，按照局部流场方向对圆点变形，将变形后的圆点用各向异性滤波器扩散到纹理中（形象地说就是将圆点按流场方向拉伸）</li><li>线积分卷积：将矢量场与白噪声进行卷积</li><li>纹理法的优点：<ul><li>致密地表征整个流场</li><li>特定的纹理特征</li><li>适合表征动态矢量场</li><li>无种子点问题</li></ul></li><li>纹理法的缺点<ul><li>计算强度大，一般需要特定的加速算法或利用图形硬件加速</li><li>特征表达不是非常直观</li></ul></li></ul></li></ul></li></ol><h3 id="张量数据可视化"><a href="#张量数据可视化" class="headerlink" title="张量数据可视化"></a>张量数据可视化</h3><ol><li>张量概念是矢量概念和矩阵概念的推广，标量是零阶张量，矢量是一阶张量，矩阵（方阵）是二阶张量，而三阶张量则好比立体矩阵，更高阶的张量用图形无法表达</li><li>张量场可视化<ul><li>基于标量场映射可视化<ul><li>标量指数法</li></ul></li><li>基于几何的方法<ul><li>图标法，超流线</li></ul></li><li>基于纹理的方法<ul><li>线积分卷积</li></ul></li></ul></li></ol><h2 id="层次数据可视化"><a href="#层次数据可视化" class="headerlink" title="层次数据可视化"></a>层次数据可视化</h2><ol><li>层次关系(即树型结构)的有效刻画，采用不同的视觉符号来表示 不同类型的关系：<ul><li>节点-链接(Node-link)<ul><li>将单个个体绘制成一个节点，节点之间的连线表示个体之间的层次关系</li><li>核心问题：如何在屏幕上放置节点；如何绘制节点及节点之间的链接关系</li></ul></li><li>空间填充(Space-filling)<ul><li>用空间中的分块区域表示数据中的个体，并用外层区域对内层区域的包围表示彼此之间的层次关系</li></ul></li><li>混合前两种方法的思路<ul><li>相邻层次图</li><li>弹性层次图</li></ul></li></ul></li></ol><h2 id="网络数据可视化"><a href="#网络数据可视化" class="headerlink" title="网络数据可视化"></a>网络数据可视化</h2><h3 id="网络关系数据"><a href="#网络关系数据" class="headerlink" title="网络关系数据"></a>网络关系数据</h3><ol><li>不具备层次结构的关系数据，可统称为网络数据</li></ol><h3 id="网络关系数据的可视化"><a href="#网络关系数据的可视化" class="headerlink" title="网络关系数据的可视化"></a>网络关系数据的可视化</h3><ol><li>图的显示<ul><li>节点链接式显示<ul><li>分层显示</li><li>力导向布局</li><li>多维尺度分析布局</li></ul></li><li>相邻矩阵</li><li>基于属性的显示</li></ul></li></ol><h3 id="图的简化"><a href="#图的简化" class="headerlink" title="图的简化"></a>图的简化</h3><ol><li>拓扑简化<ul><li>减少数据量<ul><li>减少点<ul><li>聚类</li></ul></li></ul></li><li>减少边<ul><li>最小生成树</li></ul></li></ul></li></ol><h3 id="交互"><a href="#交互" class="headerlink" title="交互"></a>交互</h3><ol><li>图可视化中的交互<ul><li>基于视点的交互：基于视点的交互是指用交互手段来预测和帮助用户在图中切换视点。视点交互中比较常规的方法包括界面的平移、缩放、旋转等操作</li><li>基于图元的交互：基于图元的交互是指对于一个可视化映射元素的交互，如节点的选择、高亮、删除、移动、展开(获取细节)与收缩</li><li>基于图结构的交互：核心思想是“焦点+上下文”(Focus+Context)技术</li></ul></li></ol><h2 id="文本数据可视化"><a href="#文本数据可视化" class="headerlink" title="文本数据可视化"></a>文本数据可视化</h2><h3 id="文本信息分析基础"><a href="#文本信息分析基础" class="headerlink" title="文本信息分析基础"></a>文本信息分析基础</h3><ol><li>分词技术和词干提取<ul><li>分词(Tokenization)，将一段文字划分为多个词项，剔除停词，从文字中提取出有意义的词项</li><li>词干提取(Stemming)，去除词缀得到词根，得到单词最一般写法<ul><li>词干提取避免了同一个词的不同表现形式对文本分析带来的干扰</li></ul></li></ul></li><li>语法分析树(或分析树，Parse Tree)，一种用于反映文本语句及其语法关系的有序树结构。</li></ol><h3 id="文本可视化"><a href="#文本可视化" class="headerlink" title="文本可视化"></a>文本可视化</h3><ol><li>文本内容可视化<ul><li>基于关键字的可视化：以关键词为单位可视地表达文本内容</li><li>时序文本可视化：对于具有时间和顺序属性的文本，文本内容具有有序演化的特点</li><li>文本特征的分布模式可视化</li><li>观点挖掘可视化：文本意见挖掘或情感分析，是对文本信息的主题、意见持有者、主客观性、情绪态度等情感信息的挖掘和分析，进而识别出主观性文本的情感趋向</li><li>查询可视化：了解搜索结果；发现结果中的分布模式</li><li>软件可视化：源代码可以看作是一种特殊类型的文本</li></ul></li><li>文本关系可视化<ul><li>文档集合中的关系<ul><li>参考文献</li><li>超链接</li><li>相似性和等级</li></ul></li><li>方法<ul><li>图形布局</li><li>树布局</li></ul></li></ul></li><li>多层次文档可视化<ul><li>文档内容</li><li>文档时空信息</li><li>作者</li></ul></li></ol><h2 id="跨媒体数据可视化"><a href="#跨媒体数据可视化" class="headerlink" title="跨媒体数据可视化"></a>跨媒体数据可视化</h2><h3 id="图像数据可视化"><a href="#图像数据可视化" class="headerlink" title="图像数据可视化"></a>图像数据可视化</h3><ol><li>图像网格</li><li>基于时空采样的图像集可视化</li><li>基于相似性的图像集可视化</li><li>基于海塞图的社交图像可视化</li><li>基于故事线的社交图像可视化</li></ol><h2 id="可视化交互与分析"><a href="#可视化交互与分析" class="headerlink" title="可视化交互与分析"></a>可视化交互与分析</h2><h3 id="可视化交互"><a href="#可视化交互" class="headerlink" title="可视化交互"></a>可视化交互</h3><ol><li>交互延时<ul><li>操作延时</li><li>反馈延时</li><li>系统更新延时</li></ul></li><li>交互成本<ul><li>达成目的选择花费的决策成本</li><li>生成系统操作花费的系统资源成本</li><li>多重输入模式引发的交互流程阻滞</li><li>人体物理动作占据的流程执行时间</li><li>视觉混叠引起的感知阻碍</li><li>视图变换花费的解读时间</li><li>评估解释中的状态转换成本</li></ul></li><li>基本交互方法<ul><li>选择</li><li>导航</li><li>重配</li><li>视觉编码</li><li>抽象化/具体化</li><li>过滤</li><li>关联</li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;绪论&quot;&gt;&lt;a href=&quot;#绪论&quot; class=&quot;headerlink&quot; title=&quot;绪论&quot;&gt;&lt;/a&gt;绪论&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;什么是可视化：利用人眼的感知能力对数据进行交互的可视表达以增强认知的技术&lt;/li&gt;
&lt;li&gt;可视化的作用&lt;ul&gt;
&lt;li&gt;记录信</summary>
      
    
    
    
    <category term="笔记" scheme="https://shuqian8421.github.io/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>线性代数笔记</title>
    <link href="https://shuqian8421.github.io/posts/54196/"/>
    <id>https://shuqian8421.github.io/posts/54196/</id>
    <published>2024-09-24T16:00:00.000Z</published>
    <updated>2025-02-12T10:38:08.581Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第一章-线性代数中的线性方程组"><a href="#第一章-线性代数中的线性方程组" class="headerlink" title="第一章 线性代数中的线性方程组"></a>第一章 线性代数中的线性方程组</h1><h2 id="线性方程组"><a href="#线性方程组" class="headerlink" title="线性方程组"></a>线性方程组</h2><p>线性方程组由一个或多个线性方程组成。例：<br>$2x_1-x_2+1.5x_3=8$<br>$\ \ x_1-\ \ \ \ \ \ \ \ \ \ \ \ 4x_3=-7$</p><p>线性方程组的解是一组数$(s_1,s_2,···,s_n)$，用这组数分别替代$x_1,x_2,···,x_n$时所有方程的两边相等。</p><p>解集：方程组所有可能的解的集合称为线性方程组的解集。</p><p>若两个线性方程组有相同的解集，则称它们为等价的。</p><p>线性方程组的解有以下三种情况：</p><ol><li>无解</li><li>有惟一解</li><li>有无穷多解</li></ol><p>方程组有解，称为方程组相容（consistent）；无解称为不相容（inconsistent）。</p><p>方程组的矩阵形式<br><img src="../../../img/posts/LinearAlgebraNotes/1.1.jpg" alt="方程组的矩阵形式"></p><p>初等行变换：</p><ol><li>（倍加变换）把某一行换成它本身与另一行的倍数的和。</li><li>（对称变换）把两行对换。</li><li>（倍乘变换）把某一行的所有元素乘以同一个非零数。</li></ol><p>一次初等行变换是可逆向进行的。A矩阵经过一次初等行变换到B矩阵，则B矩阵经过一次初等行变换到A矩阵。可以验证多次初等行变换也是可逆向进行的。</p><p>行等价（row equivalent）：两个矩阵称为行等价，如果存在一系列初等行变换使一个矩阵变到另一个矩阵。</p><p>矩阵的行等价是一种等价关系。</p><p>若两个线性方程组的增广矩阵是行等价的，则它们具有相同的解集。</p><p>方程组的基本问题：</p><ol><li>方程组相容吗？</li><li>方程组的解的个数唯一吗？<h2 id="行化简与阶梯型矩阵"><a href="#行化简与阶梯型矩阵" class="headerlink" title="行化简与阶梯型矩阵"></a>行化简与阶梯型矩阵</h2></li></ol><p>非零行的先导元素：左面第一个非零元素</p><p>矩阵如果满足下面三个条件，则称为（行）阶梯型（(row)echelon form）矩阵：</p><ol><li>每一非零行在每一零行之上；</li><li>某一行的先导元素所在的列位于前一行先导元素的右面；</li><li>某一先导元素所在列下方元素都是零。</li></ol><p>若一个阶梯型矩阵还满足以下性质，称它为简化阶梯型（(row)reduced echelon form）矩阵：</p><ol><li>每一非零行的先导元素是1；</li><li>每一先导元素1是该元素所在列的惟一非零元素。</li></ol><p>定理1（简化阶梯型矩阵的惟一性）：<br>每个矩阵行等价于惟一的简化阶梯型矩阵。</p><p>阶梯型的先导元素的位置是固定的，称为主元位置（pivot position）。</p><p>主元位置的非零元素称为主元（pivot）。</p><p>主元位置所在的列称为主元列（pivot column）。</p><p>一个矩阵的行化简得到的阶梯型不一定相同，但主元位置和主元列一定相同。</p><p>基本变量：对应于主元列的变量。</p><p>自由变量：非主元列的变量。</p><p>方程组的通解：所有解的显式表示。</p><p>定理2（存在与惟一性定理）：<br>线性方程组相容的充要条件是增广矩阵的左右列不是主元列，就是说，增广矩阵的阶梯型没有形如<br>$[0\ ··· 0 \ b]\ b\ne 0$<br>的行。若线性方程组相容，它的解集可能有两种情形：（i）当没有自由变量时，有惟一解；（ii）当至少有一个自由变量时，有无穷多解。</p><h2 id="向量方程"><a href="#向量方程" class="headerlink" title="向量方程"></a>向量方程</h2><p>仅含一列的矩阵称为列向量，或简称向量。</p><p>$w=[\begin{matrix}<br>w_1\<br>w_2\<br>\end{matrix}]$</p><p>$w_1$和$w_2$为任意实数。所有两个元素的向量的集记为$R^2$，$R$表示向量中的元素是实数，而指数2表示每个向量包含两个元素。</p><script type="math/tex; mode=display">R_2中两个向量相等，当且仅当对应元素相等。因此，[\begin{matrix}4\\7\end{matrix}]和[\begin{matrix}7\\4\end{matrix}]是不相等的。</script><script type="math/tex; mode=display">[\begin{matrix}1\\-2\end{matrix}]+[\begin{matrix}2\\5\end{matrix}]=[\begin{matrix}1+2\\-2+5\end{matrix}]=[\begin{matrix}3\\3\end{matrix}]</script><script type="math/tex; mode=display">若\mathbb{u}=[\begin{matrix} 3\\1 \end{matrix}],c=5,则c\mathbb{u}=5[\begin{matrix}3\\-1\end{matrix}]=[\begin{matrix}15\\-5\end{matrix}]</script><p>数c称为标量</p><p>$R^n$中向量的代数性质：<br>$对R^n中一切向量\mathbb{u,v,w}以及标量c和d$，  </p><ol><li>$\mathbb{u}+\mathbb{v}=\mathbb{v}+\mathbb{u}$</li><li>$(\mathbb{u}+\mathbb{v})+\mathbb{w}=\mathbb{u}+(\mathbb{v}+\mathbb{w})$</li><li>$\mathbb{u}+\mathbb{0}=\mathbb{0}+\mathbb{u}=\mathbb{u}$</li><li>$\mathbb{u}+(\mathbb{-u})=\mathbb{-u}+\mathbb{u}=\mathbb{0}$</li><li>$c(\mathbb{u}+\mathbb{v})=c\mathbb{u}+c\mathbb{v}$</li><li>$(c+d)\mathbb{u}=c\mathbb{u}+d\mathbb{u}$</li><li>$c(d\mathbb{u})=(cd)(\mathbb{u})$</li><li>$1\mathbb{u}=\mathbb{u}$</li></ol><p>$给定R^n中向量v_1,v_2,···,v_p和标量c_1,c_2,···,c_p$，向量<br>$\mathbb{y}=c_1\mathbb{v_1}+···+c_p\mathbb{v_p}$<br>称为向量$v_1,v_2,···,v_p以c_1,c_2,···,c_p为权的线性组合$。</p><p>定义：<br>若<script type="math/tex">\mathbb{v_1,v_2,···,v_p}</script>是<script type="math/tex">R^n</script>中的向量，则<script type="math/tex">\mathbb{v_1,v_2,···,v_p}</script>的所有线性组合所成的集合用记号<script type="math/tex">Span\{\mathbb{v_1,v_2,···,v_p}\}</script>表示，称为由<script type="math/tex">\mathbb{v_1,v_2,···,v_p}</script>所生成（或张成）的<script type="math/tex">R^n</script>的子集。也就是说，<script type="math/tex">Span\{\mathbb{v_1,v_2,···,v_p}\}</script>是所有形如  </p><script type="math/tex; mode=display">c_1\mathbb{v_1}+c_1\mathbb{v_2}+···+c_p\mathbb{v_p}</script><p>的向量的集合，其中<script type="math/tex">c_1,c_2,···,c_p</script>为向量。</p><h2 id="矩阵方程-A-mathbb-x-mathbb-b"><a href="#矩阵方程-A-mathbb-x-mathbb-b" class="headerlink" title="矩阵方程$A\mathbb{x}=\mathbb{b}$"></a>矩阵方程$A\mathbb{x}=\mathbb{b}$</h2><p>定义：  </p><script type="math/tex; mode=display">\begin{aligned}A\mathbb{x}&=\left[ \begin{matrix}a_1\ a_2\ ···\ a_n\end {matrix} \right] \left[ \begin{matrix}x_1\\ x_2\\ ···\\ x_n\end{matrix} \right] \\&=x_1\mathbb{a_1}+x_2\mathbb{a_2}+···+x_n\mathbb{a_n}\end{aligned}</script><p>$A\mathbb{x}=\mathbb{b}有解\iff \mathbb{b}是A的列向量的线性组合$</p><p>定理4：<br>$1. 对R^m中每个\mathbb{b}，方程A\mathbb{x}=\mathbb{b}有解。$<br>$2. R^m中的每个\mathbb{b}都是A的列的一个线性组合。$<br>$3. A的各列生成R^m。$<br>$4. A在每一行都有一个主元位置。$</p><p>定理5：  </p><ol><li>$A(\mathbb{u}+\mathbb{v})=A\mathbb{u}+A\mathbb{v}$  </li><li>$A(c\mathbb{u}=c(A\mathbb{u}))$</li></ol><h2 id="线性方程组的解集"><a href="#线性方程组的解集" class="headerlink" title="线性方程组的解集"></a>线性方程组的解集</h2><p>齐次线性方程组（Homogenous Linear System）：$A\mathbb{x}=\mathbb{0}$</p><p>平凡解（trivial solution）：$\mathbb{x}=\mathbb{0}$</p><p>非平凡解（nontrivial solution）：非0解</p><p>有非平凡解$\iff$有自由变量</p><p>齐次方程组的解的结构：几个向量张成的空间，$span{v_1,v_2,···,v_p}$。</p><p>定理6：$如果A\mathbb{x}=\mathbb{b}有解，设\mathbb{p}是一个特解，通解结构：\mathbb{p}+(A\mathbb{x}=0的通解)$</p><p>如果$A\mathbb{x}=0$只有0解，则$A\mathbb{x}=\mathbb{b}$只有一个特解。</p><p>将非齐次线性方程组右端的常数换为零，得到的齐次线性方程组称为该非齐次线性方程组的导出组。</p><h2 id="线性无关"><a href="#线性无关" class="headerlink" title="线性无关"></a>线性无关</h2><p>对于$R^n$的一系列向量${v_1,v_2,···,v_p}$，若满足<br>$x_1v_1+x_2v_2+···+x_pv_p=0$<br>有惟一的平凡解，则这组向量是线性无关的。</p><p>如果有0向量，则线性相关</p><h2 id="线性变换介绍"><a href="#线性变换介绍" class="headerlink" title="线性变换介绍"></a>线性变换介绍</h2><p>$Ax=b$</p><p>$x_1a_1+x_2a_2+···+x_na_n=b$</p><p>Ax写法强调了A作用到x的变化</p><p>线性变换：一个变换T是线性的需要满足：<br>$对于定义域内所有的向量u和v，有T(u+v)=T(u)+T(v)$<br>$对于任意向量u和任意参数c，有T(cu)=cT(u)$</p><p>矩阵变换是线性变换</p><p>线性变换的性质：  </p><ol><li><script type="math/tex; mode=display">T(0)=0</script></li><li><script type="math/tex; mode=display">T(cu+dv)=cT(u)+dT(v)</script></li></ol><h2 id="线性变换的矩阵"><a href="#线性变换的矩阵" class="headerlink" title="线性变换的矩阵"></a>线性变换的矩阵</h2><p>线性变换的标准矩阵是唯一的。</p><p>映上：<script type="math/tex">R^m中的每个b向量是至少一个R^n中x向量的像，则变换T:R^n→R^m是映上R^m的。</script></p><p>一对一：$R^m中的每个b向量是至多一个R^n中x向量的像，则变换T:R^n→R^m是一对一的。$</p><p>定理11：$T:R^n→R^m是线性变换。那么，T是单射\iff T(x)=0只有平凡解$</p><p>定理12：$T:R^n→R^m是线性变换，A是T的标准矩阵，那么$<br>$T是满射\iff A的列向量张成R^m$<br>$T是单射\iff A的列向量线性无关$</p><h1 id="第二章-矩阵代数"><a href="#第二章-矩阵代数" class="headerlink" title="第二章 矩阵代数"></a>第二章 矩阵代数</h1><h2 id="矩阵运算"><a href="#矩阵运算" class="headerlink" title="矩阵运算"></a>矩阵运算</h2><p>定理1：  </p><ol><li>A+B=B+A</li><li>(A+B)+C=A+(B+C)</li><li>A+0=A</li><li>r(A+B)=rA+rB</li><li>(r+s)A=rA+sA</li><li>r(sA)=(rs)A</li></ol><p>一般情况下，$AB\ne BA$</p><p>若$AB=AC$，一般情况下，B=C不一定成立。</p><p>定理3：  </p><ol><li>$(A^T)^T=A$</li><li>$(A+B)^T=A^T+B^T$</li><li>$任意数r，(rA)^T=rA^T$</li><li>$(AB)^T=B^TA^T$</li></ol><h2 id="矩阵的逆"><a href="#矩阵的逆" class="headerlink" title="矩阵的逆"></a>矩阵的逆</h2><p>对于n×n矩阵A，若有一个n×n矩阵C满足$CA=AC=I_n$，则A是可逆的。C是A的逆矩阵。</p><p>逆矩阵有唯一性。</p><p>不可逆的矩阵叫奇异矩阵，可逆矩阵叫非奇异矩阵。</p><p>定理5：$若A是n×n矩阵，则R^n中的每个向量b，Ax=b有唯一解x=A^{-1}b$</p><p>定理6：  </p><ol><li>$(A^{-1})^{-1}=A$</li><li>$(AB)^{-1}=B^{-1}A^{-1}$</li><li>$(A^T)^{-1}=(A^{-1})^T$</li></ol><p>对单位矩阵进行一次初等行变换，得到初等矩阵。</p><p>初等矩阵E左乘一个矩阵A，EA $\iff$ 对A进行对应的初等行变换。</p><p>初等矩阵E是可逆的。</p><p>定理7：$n\times n矩阵可逆 \iff A行等价于I$</p><h2 id="可逆矩阵的特征"><a href="#可逆矩阵的特征" class="headerlink" title="可逆矩阵的特征"></a>可逆矩阵的特征</h2><p>定理8（可逆矩阵定理）：</p><ol><li>A是可逆矩阵。</li><li>$A等价于n \times n单位矩阵。$</li><li>A有n个主元位置。</li><li>方程Ax=0仅有平凡解。</li><li>A的各列线性无关。</li><li>线性变换$x|→Ax$是一对一的。</li><li>$对R^n中的任意b，Ax=b至少有一个解。$</li><li>$A的各列生成R^n$</li><li>$线性变换x|→Ax把R^n映上到R^n上。$</li><li>$存在n \times n的矩阵C使CA=I$</li><li>$存在n \times n的矩阵使AD=I$</li><li>$A^T是可逆矩阵$</li></ol><h2 id="分块矩阵"><a href="#分块矩阵" class="headerlink" title="分块矩阵"></a>分块矩阵</h2><p>定理10：若A是m×n矩阵，B是n×p<br>矩阵，则<br>$AB=[col_1(A)\ col_2(A)\ ··· col_n(A)] \left[ \begin{matrix} row_1(B)\<br>row_2(B)\<br>···\<br>row_n(B)<br>\end{matrix} \right]$</p><h2 id="矩阵因式分解"><a href="#矩阵因式分解" class="headerlink" title="矩阵因式分解"></a>矩阵因式分解</h2><p>LU分解</p><p><img src="../../../img/posts/LinearAlgebraNotes/2.1.jpg" alt="例"></p><h1 id="第三章-行列式"><a href="#第三章-行列式" class="headerlink" title="第三章 行列式"></a>第三章 行列式</h1><h2 id="行列式介绍"><a href="#行列式介绍" class="headerlink" title="行列式介绍"></a>行列式介绍</h2><p>矩阵A的行列式记为detA</p><p>去掉第i行第j列所在的行和列，得到的子矩阵$A<em>{ij}$，叫A的子行列式（也叫余子式）。$C</em>{ij}=(-1)^{i+j}detA_{ij}$是A的代数余子式。</p><p>定理1：$det A = a<em>{i1}C</em>{i1}+a<em>{i2}C</em>{i2}+···+a<em>{in}C</em>{in}$</p><p>定理2：三角矩阵的行列式等于主对角线上元素的乘积。</p><h2 id="行列式的性质"><a href="#行列式的性质" class="headerlink" title="行列式的性质"></a>行列式的性质</h2><p>定理3 设A是一个方阵，则：  </p><ol><li>矩阵A的一行的乘积加到另一行得到矩阵B，detA=detB.</li><li>矩阵A的两行交换得到矩阵B，则detB=-detA.</li><li>矩阵A的一行乘k得到矩阵B，则detB=k·detA.</li></ol><p>定理4：$方阵A可逆\iff detA \ne 0$</p><p>定理5：$若A是一个n \times n矩阵，则detA^T=detA$</p><p>定理6：若A、B是一个n×n矩阵，则detAB=(detA)(detB)</p><h2 id="克拉默法则、体积和线性变换"><a href="#克拉默法则、体积和线性变换" class="headerlink" title="克拉默法则、体积和线性变换"></a>克拉默法则、体积和线性变换</h2><p>对于方程组Ax=b，记：$A_i(b)=[a_1 ··· b ··· a_n]$</p><p>定理7（Cramer法则）：A是可逆的n×n矩阵，Ax=b的惟一解是$x_i=\frac{detA_i(b)}{detA}$</p><p>定理8（逆矩阵公式）：设A是一个可逆的n×n矩阵则$A^{-1}=\frac{1}{detA}adjA$<br>其中<script type="math/tex">adjA=\left[ \begin{matrix}C_{11} & C_{21} & ··· & C_{n1}\\C_{12} & C_{22} & ··· & C_{n2}\\··· & ··· & ··· & ···\\C_{1n} & C_{2n} & ··· & C_{nn}\end{matrix}\right]</script></p><h1 id="第四章-向量空间"><a href="#第四章-向量空间" class="headerlink" title="第四章 向量空间"></a>第四章 向量空间</h1><h2 id="向量空间与子空间"><a href="#向量空间与子空间" class="headerlink" title="向量空间与子空间"></a>向量空间与子空间</h2><p>向量空间V的子空间是V的一个子集H且满足：  </p><ol><li>V中的零向量在H中。</li><li>H内的任意的u、v两向量，u+v也在H内。</li><li>H内的任意向量u和任意数c，cu在H内。</li></ol><p>只有0向量的空间是任何向量空间的子空间，称为0空间，写作{0}</p><p>$R^2不是R^3的子空间，因为R^2不是R^3的子集$</p><p>称<script type="math/tex">\mathrm{Span} \{v_1,v_2,···,v_p\}为\{v_1,···,v_p\}</script>张成的子空间</p><h2 id="零空间、列空间和线性变换"><a href="#零空间、列空间和线性变换" class="headerlink" title="零空间、列空间和线性变换"></a>零空间、列空间和线性变换</h2><p>满足Ax=0的所有x的集合为矩阵A的零空间</p><p>m×n矩阵A的列空间ColA是A列向量所有线性组合的集合。</p><p>定理3：m×n矩阵A的列空间是$R^m$的子空间</p><p><img src="../../../img/posts/LinearAlgebraNotes/2.2.jpg" alt=""></p><p>线性变换的核是V中满足T(u)=0的所有向量u的集合。</p><h2 id="线性无关集和基"><a href="#线性无关集和基" class="headerlink" title="线性无关集和基"></a>线性无关集和基</h2><p>设H是向量空间V的一个子空间，V中的向量集$B={b_1,b_2,···,b_p}$称为H的一组基，如果：<br>(i)B是线性无关集<br>(ii)B生成H，即$H=Span{b_1,···,b_p}$</p><p>矩阵的行初等变换不改变列向量的相关性</p><p>定理6：矩阵A的主元列是colA的一组基。</p><h2 id="坐标系"><a href="#坐标系" class="headerlink" title="坐标系"></a>坐标系</h2><p>令$B={b_1,b_2,···,b_n}$是向量空间V的一组基，则对于V中的任一向量x，存在唯一一组标量$c_1,···,c_n$使得$x=c_1b_1+···+c_nb_n$</p><p>坐标映射是一一对应线性变换</p><h2 id="向量空间的维数"><a href="#向量空间的维数" class="headerlink" title="向量空间的维数"></a>向量空间的维数</h2><p>如果向量空间V有一组基$B={b_1,···,b_n}$，那么V中任何多于n个的向量集合一定是线性相关的。</p><p>定理10：如果向量空间V有一组基有n个向量，那么它的每一组基都有n个向量。</p><p>NulA的维数是自由变量的个数，ColA的维数是主元列的个数。自由变量的个数+主元列的个数=A的列数</p><h2 id="秩"><a href="#秩" class="headerlink" title="秩"></a>秩</h2><p>A的行向量生成的空间称为行空间，记为rowA。</p><p>$colA^T$和rowA是相同的空间</p><p>行化简改变行向量之间的线性相关性，但不改变行空间的维数，不改变行空间；行化简不改变列向量之间的线性相关性，不改变列空间的维数，但改变列空间。</p><p>定理13：两个矩阵A、B行等价，则行空间相同，如果B矩阵式阶梯型，则其非零行向量就是行空间的基。</p><p>行空间和列空间的维数相等，称为矩阵A的秩。</p><p>m×n矩阵A：rankA+dimNulA=n</p><p>可逆矩阵定理（续2.3节）</p><ol><li>A的列构成$R^n$的一个基</li><li>$ColA=R^n$</li><li>dimColA=n<br>16.rankA=n</li><li>NulA={0}</li><li>dim NulA=0</li></ol><h2 id="基的变换"><a href="#基的变换" class="headerlink" title="基的变换"></a>基的变换</h2><p>$设B={b_1,···,b_n}和C={c_1,···,c_n}是向量空间V的基，则存在一个n \times n的矩阵\underset{C←B}{P}使[x]_C=\underset{C←B}{P}[x]_B$<br>$\underset{C←B}{P}$称为B到C的坐标变换矩阵。</p><p>定理15：坐标变换矩阵的列向量使线性无关的<br>于是成立<script type="math/tex">\big(\underset{C←B}{P}\big)^{-1}[x]_C=[x]_B</script> <script type="math/tex">\big(\underset{C←B}{P}\big)^{-1}=\underset{B←C}{P}</script></p><h1 id="第五章-特征值与特征向量"><a href="#第五章-特征值与特征向量" class="headerlink" title="第五章 特征值与特征向量"></a>第五章 特征值与特征向量</h1><h2 id="特征向量与特征值"><a href="#特征向量与特征值" class="headerlink" title="特征向量与特征值"></a>特征向量与特征值</h2><p>对于n×n的矩阵A，如果存在x（≠0）满足：Ax=λx（λ为标量），则称x为特征向量，λ称为该特征向量的特征值。</p><p>特征向量一定≠0，特征值可以是0</p><p>对于一个特征值λ，方程组的零空间称为λ的特征空间。特征空间中的向量都是λ的特征向量（0除外）</p><p>定理1：三角形矩阵的特征值是对角线的元素</p><h2 id="特征方程"><a href="#特征方程" class="headerlink" title="特征方程"></a>特征方程</h2><p><img src="../../../img/posts/LinearAlgebraNotes/5.1.jpg" alt=""></p><p>det(A-λI)=0称为特征方程</p><p>det(A-λI)称为特征多项式</p><p>n×n矩阵A和B，如果存在矩阵P，使得$A=PBP^{-1}$，则称A相似于B。</p><p>A相似于B，则B相似于A。称为A和B相似。</p><p>定理4：如果n×n矩阵A和B相似，则有相同的特征值（重数也相同）。</p><p>相似不改变特征值，行等价改变特征值</p><p>相似不改变行列式的值，行等价改变行列式的值。</p><p>相似和行等价都是等价关系，都不改变维数、秩。</p><h2 id="对角化"><a href="#对角化" class="headerlink" title="对角化"></a>对角化</h2><p>$A=PDP^{-1}$，其中D是对角线矩阵</p><p>如果存在矩阵P和D，使得$A=PDP^{-1}$，则称A可对角化</p><p>定理5：n×n矩阵A可对角化$\iff$ A有n个线性无关的特征向量。</p><p>可对角化条件：存在矩阵P和D，使得$A=PDP{-1}$，此时P的各列都是A的特征向量，D的对角线元素是A的特征值。</p><p>定理6：n×n矩阵如果有n不同的特征值，则可对角化。</p><h1 id="第六章-正交性和最小二乘法"><a href="#第六章-正交性和最小二乘法" class="headerlink" title="第六章 正交性和最小二乘法"></a>第六章 正交性和最小二乘法</h1><h2 id="内积、长度与正交性"><a href="#内积、长度与正交性" class="headerlink" title="内积、长度与正交性"></a>内积、长度与正交性</h2><p>$u^Tv$称作u和v的内积，记为u·v，也成为点积。</p><p>$u·v=v·u$</p><p>定理1：u，v，w是$R^n$中的向量，c是常数。则  </p><ol><li>$u · v = v · u$</li><li>$(u + v) · w = u · w + v · w$</li><li>$(cu)·v=c(u·v)=u·(cv)$</li><li>$u·u\ge 0 且u·u=0\iff u=0$</li></ol><p>$R^n$中的两个向量u、v如果u·v=0则成为互相垂直（正交）。</p><p>0向量与所有向量正交。</p><h2 id="正交集"><a href="#正交集" class="headerlink" title="正交集"></a>正交集</h2><p>$R^n中的几个向量{u_1,···,u_p}，如果任两个不同向量都正交，则称为正交向量集。$</p><h2 id="格拉姆-施密特方法"><a href="#格拉姆-施密特方法" class="headerlink" title="格拉姆-施密特方法"></a>格拉姆-施密特方法</h2><p><img src="../../../img/posts/LinearAlgebraNotes/6.1.jpg" alt=""></p><p><img src="../../../img/posts/LinearAlgebraNotes/6.2.jpg" alt=""></p><h2 id="最小二乘问题"><a href="#最小二乘问题" class="headerlink" title="最小二乘问题"></a>最小二乘问题</h2><p>$A^TAx=A^Tb$</p><p>定理14：$A^TA可逆\iff A的列向量线性无关$</p><h1 id="第七章-对称矩阵和二次型"><a href="#第七章-对称矩阵和二次型" class="headerlink" title="第七章 对称矩阵和二次型"></a>第七章 对称矩阵和二次型</h1><h2 id="对称矩阵的对角化"><a href="#对称矩阵的对角化" class="headerlink" title="对称矩阵的对角化"></a>对称矩阵的对角化</h2><p>满足$A^T=A的矩阵A是对称矩阵$</p><p>对称矩阵一定是方阵</p><p>可正交对角化：$A=PDP^T=PDP^{-1}$ 一定是对称矩阵</p><p>定理2：一个n×n矩阵可正交对角化$\iff$ A是对角矩阵</p><h2 id="二次型"><a href="#二次型" class="headerlink" title="二次型"></a>二次型</h2><p>二次型是二次函数$Q(x)=x^TAX$其中A是n×n对称矩阵，称为二次型的矩阵。</p><p>二次型可通过变量代换去掉交叉乘积项。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;第一章-线性代数中的线性方程组&quot;&gt;&lt;a href=&quot;#第一章-线性代数中的线性方程组&quot; class=&quot;headerlink&quot; title=&quot;第一章 线性代数中的线性方程组&quot;&gt;&lt;/a&gt;第一章 线性代数中的线性方程组&lt;/h1&gt;&lt;h2 id=&quot;线性方程组&quot;&gt;&lt;a hre</summary>
      
    
    
    
    <category term="笔记" scheme="https://shuqian8421.github.io/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>Notes for STAT_PROB_2024 Review Course on Probability and Statistics [2024]</title>
    <link href="https://shuqian8421.github.io/posts/41305/"/>
    <id>https://shuqian8421.github.io/posts/41305/</id>
    <published>2024-08-27T16:00:00.000Z</published>
    <updated>2025-02-12T10:38:08.580Z</updated>
    
    <content type="html"><![CDATA[<div class="tabs" id="head"><ul class="nav-tabs no-default"><button type="button" class="tab " data-href="head-1">Course Information</button></ul><div class="tab-contents"><div class="tab-item-content" id="head-1"><ul><li>Course Name: STAT_PROB_2024 Review Course on Probability and Statistics [2024]</li><li>Instructor: Dr. Olivia T.K. Choi Office: Room 208, Run Run Shaw Building P: 3917-1985 E: ochoi@hku.hk</li><li>Classes: This course is offered as pre-recorded online video. The videos are available on Moodle on the following dates: August12, 15, 19 and 22, 2024</li><li>Course Objectives: This course is designed for students newly admitted to the HKU Master of Statistics / Master of Data Science programmes, and serves as a review of basic probability and statistical concepts that are needed for the courses in these programmes. </li><li>Course Contents and Topics: </li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">Chapter</th><th style="text-align:center">Topics</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center"><strong>Basic probability theory</strong>: Set; event; probability; conditional probability; Bayes’ rule; random variable; density/mass function and distribution function.</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center"><strong>Distributions and moments</strong>: Bivariate distribution; joint, marginal and conditional distributions; expectation; variance; raw and central moments; higher moment; moment-generating function; covariance and correlation; iterated moments; common parametric distributions.</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center"><strong>Sampling and estimation</strong>: Sample mean and variance; law of large numbers; central limit theorem; properties of point estimators; method of moments; maximum likelihood; interval estimation and confidence interval.</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center"><strong>Hypothesis testing</strong>: Null and composite hypotheses; test statistic; type I/II errors; power function; p -value; duality principle; hypothesis tests regarding means, variances and proportions.</td></tr></tbody></table></div><ul><li>Assessment: This course is optional and no assessment is assigned. Students are however encouraged to solidify their conceptual understanding by attempting the exercises in the reference texts. </li><li>Reference text books:<br>Miller, I. and Miller, M.: John E. Freund’s Mathematical Statistics with Applications (2014, 8th edition)<br>DeGroot, M. H. and Schervish, M. J.: Probability and Statistics (2012, 4th edition)<br>Ross, S.: A First Course in Probability (2012, 9th edition)</li></ul></div></div><div class="tab-to-top"><button type="button" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div><h1 id="Basic-Probability-Theory"><a href="#Basic-Probability-Theory" class="headerlink" title="Basic Probability Theory"></a>Basic Probability Theory</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>We will review the following topics:</p><ol><li><strong>Basic probablilty theory</strong>: Set; event; probability; Bayes’ rule; random variable; density/mass/distribution functions.</li><li><strong>Distributions and moments</strong>: Joint/marginal/conditional distributions; moment and generating functions; covariance and correlation; iterated moments; common parametric distributions.</li><li><strong>Sampling and estimation</strong>: Sample mean and variance; large sample theories; properties of point estimators; method of moments; maximum likelihood; interval estimation and confidence interval.</li><li><strong>Hypothesis testing</strong>: Null and composite hypotheses; test statistic; type I/II errors; power functions; p-value; duality principle; hypothesis tests regarding means, variances and proportions.</li></ol><h2 id="Sets-events-and-probability"><a href="#Sets-events-and-probability" class="headerlink" title="Sets, events and probability"></a>Sets, events and probability</h2><h3 id="Sets-and-events"><a href="#Sets-and-events" class="headerlink" title="Sets and events"></a>Sets and events</h3><ol><li>A sample space is a set containing all possible outcomes.<br>An event is a subset of the sample space.An empty event is the empty set.</li><li>For two or more sets, the <strong>intersection operator</strong> $\cap$ extracts elements common to both sets.<br>The intersection of sets cannot have more elements than the individual sets.</li><li>For two or more sets, the <strong>union operator</strong> $\cup$ combines elements from<br>both sets.<br>The union of sets cannot have fewer elements than the individual sets.</li><li>Two sets $E_1$ and $E_2$ are disjoint if $E_1 \cap E2 = \emptyset$ (nothing in common).</li><li>The sets $E_1,E_2,\dots,E_n$:<ul><li>are <strong>mutually exclusive</strong> if $E_i \cap E_j = \emptyset$ for all $i \ne j$</li><li>are <strong>exhaustive</strong> if $E_1 \cup \dots \cup E_n = \Omega$, (make up the sample space);</li><li>form a <strong>partition</strong> if the above two properties are true.</li></ul></li><li>The <strong>complement</strong> of a set $E$ is a set that contains all elements <em>not</em> in $E$, denoted as $E^c$.</li></ol><h3 id="Probability-of-events"><a href="#Probability-of-events" class="headerlink" title="Probability of events"></a>Probability of events</h3><ol><li>The probability operator $\mathbb{P}$ assigns a number to each event to denote its “likelihood” of happening.<ul><li>$\mathbb{P}(\emptyset) = 0, \mathbb{P}(\Omega) = 1$;</li><li>$\mathbb{P}(E) \ge 0$ for any event $E$;</li><li>$\mathbb{P}(E) + \mathbb{P}(E^c) = 1$;</li><li>For mutually exclusive events $E_1,\dots,E_n, \mathbb{P}$ is additive, i.e.,<script type="math/tex; mode=display">\mathbb{P}(E_1\cup E_2\cup\dots E_n) = \mathbb{P}(E_1) + \mathbb{P}(E_2) + \dots + \mathbb{P}(E_n)</script></li></ul></li><li>The <strong>inclusion-exclusion formula</strong> is extremely useful to convert the probabilities of $\cup$ to $\cap$, and vice versa:<script type="math/tex; mode=display">\mathbb{P}(\bigcup_{i=1}^n E_i)= \sum_{i} \mathbb{P}(E_i) - \sum_{i<j} \mathbb{P}(E_i\cap E_j) + \sum_{i<j<k} \mathbb{P}(E_i\cap E_j \cap E_k) + \dots + (-1)^{n+1}\mathbb{P}(\bigcap_{i=1}^n E_i)</script>We typically use it for 2 or 4 events, i.e.,<script type="math/tex; mode=display">\mathbb{P}(E_1\cup E_2) = \mathbb{P}(E_1) + \mathbb{P}(E_2) - \mathbb{P}(E_1\cap E_2)</script><script type="math/tex; mode=display">\mathbb{P}(E_1\cup E_2 \cup E_3) = \mathbb{P}(E_1)+\mathbb{P}(E_2)+\mathbb{P}(E_3)-\mathbb{P}(E_1\cap E_2)-\mathbb{P}(E_1\cap E_3)-\mathbb{P}(E_2\cap E_3)+\mathbb{P}(E_1\cap E_2\cap E_3)</script></li></ol><h2 id="Conditional-probability"><a href="#Conditional-probability" class="headerlink" title="Conditional probability"></a>Conditional probability</h2><h3 id="Probabilities-conditional-on-given-information"><a href="#Probabilities-conditional-on-given-information" class="headerlink" title="Probabilities conditional on given information"></a>Probabilities conditional on given information</h3><p>Sometimes, we deal with probabilities on the condition that we know something in advance.</p><h3 id="Calculating-conditional-probabilities"><a href="#Calculating-conditional-probabilities" class="headerlink" title="Calculating conditional probabilities"></a>Calculating conditional probabilities</h3><ol><li>Definition: Conditional probability<br>For two events $A$ and $B$, the <strong>conditional probability</strong> of event $A$ given the occurrence of event $B$ is written as $\mathbb{P}(A|B)$, calculated as<script type="math/tex; mode=display">\mathbb{P}(A|B) = \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}</script>if $\mathbb{P}(B)&gt;0$.<br>This example simply reinstates that $\mathbb{P}(A\cap B)= \mathbb{P}(B)\mathbb{P}(A|B)$</li><li>Theorem: Law of total probability<br>For events $B_1,\dots, B_n$ that form a partition (i.e., mutually exclusive &amp;<br>exhaustive) and event $A$,<script type="math/tex; mode=display">\mathbb{P}(A) = \sum_{i=1}^n \mathbb{P}(A\cap B_i) = \sum_{i=1}^n \mathbb{P}(B_i)\mathbb{P}(A|B_i)</script></li><li>Theorem: Multiplication rule<br>For events $B_1,\dots,B_n$<script type="math/tex; mode=display">\mathbb{P}(\bigcap_{i=1}^n B_i) = \mathbb{P}(B_1)\mathbb{P}(B_2|B_1)\mathbb{P}(B_3|B_1\cap B_2)\dots \mathbb{P}(B_n|\bigcap_{i=1}^{n-1}B_i)</script></li></ol><h3 id="Independent-events"><a href="#Independent-events" class="headerlink" title="Independent events"></a>Independent events</h3><ol><li>Two events $A$ and $B$ are said to be <strong>independent</strong> (written as $A \perp\kern-5pt\perp B$) if $P(A) = P(A|B)$, i.e., occurrence of $B$ does not affect the chances of $A$ happening. This implies $\mathbb{P}(A \cap B) = \mathbb{P}(A) \mathbb{P}(B)$<br>This can be extended to more than two events: Events $A_1,\dots,A_n$ are <strong>mutally independent</strong> if and only if<script type="math/tex; mode=display">\mathbb{P}(A_{k_1}\cap\dots\cap A_{k_m}) = \mathbb{P}(A_{k_1})\mathbb{P}(A_{k_2})\dots \mathbb{P}(A_{k_m})</script>for <em>every</em> combination of $k_1\ne k_2\ne\dots\ne k_m$ and $m\le n$</li></ol><h3 id="Bayes’-rule"><a href="#Bayes’-rule" class="headerlink" title="Bayes’ rule"></a>Bayes’ rule</h3><ol><li>Theorem: Bayes’ rule<br>For two events $A$ and $B$ with $\mathbb{P}(A)\gt 0$ and $\mathbb{P}(B)\gt 0$<script type="math/tex; mode=display">\mathbb{P}(B|A)=\frac{\mathbb{P}(A|B)\mathbb{P}(B)}{\mathbb{P}(A)}</script>$\mathbb{P}(B)$ is known as the <strong>prior probability</strong> and $\mathbb{P}(B|A)$ the <strong>posterior probability</strong>.<br>$\mathbb{P}(B)=\mathbb{P}(B|A)\iff \mathbb{P}(A)=\mathbb{P}(A|B)$,i.e., $A$ and $B$ are independent and thus $A$ adds no information on $B$.</li><li>In general, if $B_1,\dots,B_n$ constitute a partition, then<script type="math/tex; mode=display">\mathbb{P}(B_j|A) = \frac{\mathbb{P}(A|B_j)\mathbb{P}(B_j)}{\sum_{i=1}^n \mathbb{P}(A|B_i)\mathbb{P}(B_i)}</script></li></ol><h2 id="Random-variables-and-distributions"><a href="#Random-variables-and-distributions" class="headerlink" title="Random variables and distributions"></a>Random variables and distributions</h2><h3 id="Random-variables"><a href="#Random-variables" class="headerlink" title="Random variables"></a>Random variables</h3><ol><li><p>A <strong>random variable</strong> is a function that maps each element of the sample space to a real number.</p><p>A random variable is <em>realized</em> when we observe its value. We typically use capital letters (e.g., $X$, $Y$) to denote random variables and small letters (e.g., $x$, $y$) to denote their realizations.</p><p>There are three main types of random variables — <strong>discrete</strong>, <strong>continuous</strong>, and <strong>mixed</strong>.</p></li><li><p>Discrete random variables — pmf<br>A random variable $X$ is <strong>discrete</strong> if it can only take on a countable (possibly countably infinite) number of values.</p><p>Definition: Probability mass function<br>For a discrete random variable $X$, the <strong>probability mass function</strong> or pmf is defined as</p><script type="math/tex; mode=display">p_X(x):=\mathbb{P}(X=x)</script><p>for $x\in X(\Omega)$, where $X(\Omega)$ is the set of all possible values of $X$<br>A valid pmf has the following properties:</p><ul><li>$p_X(x)\ge 0$ for all $x$</li><li><script type="math/tex; mode=display">\sum_{x\in X(\Omega)}p_X(x) = 1</script></li><li>For any subset $A\subset X(\Omega)$,$\mathbb{P}(X\in A)=\sum_{x\in A}p_X(x)$.</li></ul></li><li>Discrete random variables — cdf<br>Definition: Cumulative distribution function<br>For a discrete random variable $X$, the <strong>cumulative distribution function</strong> or cdf is defined as<script type="math/tex; mode=display">F_X(x):=\mathbb{P}(X\le x)=\sum_{i\le x}p_X(i)</script>for $x \in \mathbb{R}$.It is often shortened as the <strong>distribution function</strong> of $X$.<br>A valid cdf has the following properties:<ul><li>$F_X(a)\le F_X(b)$ if $a\le b$</li><li><script type="math/tex; mode=display">\lim_{x\rightarrow-\infty} F_X(x)=0; \lim_{x\rightarrow\infty} F_X(x)=1</script></li><li>$F_X(x)$ is right-continuous</li><li><script type="math/tex; mode=display">\mathbb{P}(a\lt X\le b) = F(b)-F(a)</script></li></ul></li><li><p>Continuous random variables — pdf<br>Definition: Continuous random variable<br>A random variable $X$ is (absolutely) <strong>continuous</strong> if there exists a non-negative function $f$ defined on the real line such that</p><script type="math/tex; mode=display">\mathbb{P}(a\le X\le b)=\int_a^b f(x) \mathrm{d}x</script><p>for every $a\le b$, The function $f(x)$ is known as the <strong>probability density function</strong>(pdf) of $X$.</p><p>A valid pdf has the following properties:</p><ul><li>$f(x)\ge 0$ for all $x$.</li><li><script type="math/tex; mode=display">\int_{-\infty}^{\infty}f(x)\mathrm{d}x = \mathbb{P}(-\infty\le X\le \infty) = 1</script></li><li>$\int_A f(x)\mathrm{d}x=\mathbb{P}(X\in A)$ where $A$ is any subset of $\mathbb{R}$</li></ul></li><li>Continuous random variables — cdf<br>Definition: Cumulative distribution function<br>For a continuous random variable $X$, the (cumulative) <strong>distribution function</strong> or cdf is defined as<script type="math/tex; mode=display">F_X(x):=\mathbb{P}(X\le x) = \int_{-\infty}^x f_X(t)\mathrm{d}t</script>for $x\in\mathbb{R}$.</li><li>Mixed random variables<br>This is known as a mixed random variable which has probability masses at some locations and densities at other locations.</li></ol><h1 id="More-on-Distributions-and-Moments"><a href="#More-on-Distributions-and-Moments" class="headerlink" title="More on Distributions and Moments"></a>More on Distributions and Moments</h1><h2 id="Bivariate-distributions"><a href="#Bivariate-distributions" class="headerlink" title="Bivariate distributions"></a>Bivariate distributions</h2><ol><li>Joint distributions<ul><li>Definition: Joint cumulative distribution function for 2 variables<br>For two random variables $X$ and $Y$ , the <strong>joint</strong> (cumulative) <strong>distribution function</strong> or joint cdf is defined as<script type="math/tex; mode=display">F_{X,Y}(x,y):=\mathbb{P}(X\le x, Y\le y)</script>for $(x,y)\in \mathbb{R}^2$</li><li>Definition: Joint probability mass function $X$ and $Y$ are jointly discrete if there exists a <strong>joint probability mass function</strong> (joint pmf) such that<script type="math/tex; mode=display">p_{X,Y}(x,y):=\mathbb{P}(X=x,Y=y);F_{X,Y}(x,y)=\sum_{i\le x}\sum_{j\le y}p_{X,Y}(i,j)</script></li><li>Definition: Joint probability density function $X$ and $Y$ are jointly continuous if there exists a <strong>joint probability density function</strong> (joint pdf) such that<script type="math/tex; mode=display">f_{X,Y}(x,y)\le 0\space \mathrm{for}\space \mathrm{all}\space x,y; F_{X,Y}(x,y)=\int_{-\infty}^y\int_{-\infty}^x f_{X,Y}(s,t)\mathrm{d}s \mathrm{d}t</script></li></ul></li><li>Marginal distributions<ul><li>Definition: Marginal pmf/pdf<br>For $X$ and $Y$ jointly discrete, the <strong>marginal pmf</strong> of $X$ and $Y$ are respectively given by<script type="math/tex; mode=display">p_X(x) = \mathbb{P}(X=x)=\sum_{y}p_{X,Y}(x,y); p_Y(y) = \mathbb{P}(Y=y)=\sum_{x}p_{X,Y}(x,y)</script>For $X$ and $Y$ jointly continuous, the <strong>marginal pdf</strong> of $X$ and $Y$ are respectively given by<script type="math/tex; mode=display">f_X(x) = \int_{\mathbb{R}} f_{X,Y}(x,y)\mathrm{d}y; f_Y(y) = \int_{\mathbb{R}} f_{X,Y}(x,y)\mathrm{d}x</script></li></ul></li><li>Conditional distributions<ul><li>Definition: Conditional pmf/pdf<br>For $X$ and $Y$ jointly discrete, the <strong>conditional pmf</strong> of $Y$ given $X$ is<script type="math/tex; mode=display">p_{Y|X}(y|x):=\mathbb{P}(Y=y|X=x)=\frac{\mathbb{P}(X=x,Y=y)}{\mathbb{P}(X=x)}=\frac{p_{X,Y}(x,y)}{p_X(x)}</script>if $p_X(x)\gt 0$.<br>For $X$ and $Y$ jointly continuous, the <strong>conditional pdf</strong> of Y given X is<script type="math/tex; mode=display">f_{Y|X}(y|x) = \frac{f_{X,Y}(x,y)}{f_X(x)}</script>if $f_X(x)\gt 0$.</li><li>The conditional cdf can be obtained from the conditional pmf/pdf:<script type="math/tex; mode=display">F_{Y|X}(y|x) = \left\{ \begin{array}{ll} \sum_{i\le y} p_{Y|X}(i|x), & \mathrm{if\space discrete;} \\ \int_{-\infty}^y f_{Y|X}(t|x)\mathrm{d}t & \mathrm{if\space continuous.} \\ \end{array}  \right.</script></li></ul></li><li>Independence of random variables<ul><li>Definition: Independent random variables<br>Two random variables $X$ and $Y$ are <strong>independent</strong> if and only if the joint pmf/pdf is equal to the product of the marginal pmf’s/pdf’s, i.e.,<script type="math/tex; mode=display">p_{X,Y}(x,y) = p_X(x) p_Y(y)\space \mathrm{(discrete);}</script><script type="math/tex; mode=display">f_{X,Y}(x,y) = f_X(x) f_Y(y)\space \mathrm{(continuous);}</script>for all possible values of $x$ and $y$.</li><li>The above definition also works for cdf’s, i.e.,<br>$F_{X,Y}(x,y) = F_X(x) F_Y(y)$ for all $x$ and $y$.</li></ul></li></ol><h2 id="Expectations-and-moments"><a href="#Expectations-and-moments" class="headerlink" title="Expectations and moments"></a>Expectations and moments</h2><h3 id="Mathematical-expectations"><a href="#Mathematical-expectations" class="headerlink" title="Mathematical expectations"></a>Mathematical expectations</h3><ol><li>Definition: Expectation<ul><li>The <strong>expectation</strong> of a random variable $X$ (written as $\mathbb{E}(X)$) is defined as<script type="math/tex; mode=display">\mathbb{E}(X) = \left\{\begin{array}{ll}\sum_x x p_X(x), & \mathrm{if\space} X \mathrm{\space is\space discrete;} \\\int_{\mathbb{R}}x f_X(x)\mathrm{d}x & \mathrm{if\space} X \mathrm{\space is\space continuous.} \\\end{array}\right.</script></li><li>The expectation of g(X), a (known) function of X, can be defined similarly:<script type="math/tex; mode=display">\mathbb{E}[g(X)] = \left\{\begin{array}{ll}\sum_x g(x) p_X(x), & \mathrm{if\space} X \mathrm{\space is\space discrete;} \\\int_{\mathbb{R}}g(x) f_X(x)\mathrm{d}x & \mathrm{if\space} X \mathrm{\space is\space continuous.} \\\end{array}\right.</script></li><li>We say that the expectation (of $X$ or $g(X)$) does not exist if the sum or integral diverges.</li><li>Properties of the expectation operator:<ol><li>$\mathbb{E}(aX+b)=a\mathbb{E}(X)+b$ for any constants $a$, $b$ and random variable $X$. We call $\mathbb{E}$ a linear operator.</li><li>If $X\le Y$ for all possible outcomes in the sample space, then $\mathbb{E}(X) \le \mathbb{E}(Y)$.</li><li>If $\mathbb{E}|X^a|$ exists for some $a \gt 0$, then $\mathbb{E}|X^b|$ exists for all $0 \lt b \lt a$. This also implies the existence of $\mathbb{E}(X^b)$.</li></ol></li></ul></li><li>Moments<ul><li>Definition: Moments<br>The $n$th <strong>raw moment</strong> of a random variable $X$ is defined as<script type="math/tex; mode=display">\mathbb{E}(X^n) = \left\{\begin{array}{ll}\sum_x x^n p_X(x), & \mathrm{if\space} X \mathrm{\space is\space discrete;} \\\int_{\mathbb{R}}x^n f_X(x)\mathrm{d}x & \mathrm{if\space} X \mathrm{\space is\space continuous.} \\\end{array}\right.</script>if it exists. The first raw moment is also known as the <strong>mean</strong> of $X$, often denoted by $\mu$.<br>The $n$th <strong>central moment</strong> of a random variable $X$ is defined as<script type="math/tex; mode=display">\mathbb{E}[(X-\mu)^n] = \left\{\begin{array}{ll}\sum_x (x-\mu)^n p_X(x), & \mathrm{if\space} X \mathrm{\space is\space discrete;} \\\int_{\mathbb{R}}(x-\mu)^n f_X(x)\mathrm{d}x & \mathrm{if\space} X \mathrm{\space is\space continuous.} \\\end{array}\right.</script>if it exists.</li></ul></li><li>Means, variances and standard deviations<ul><li>Raw moments are moments about the origin; central moments are moments about the mean.</li><li>Definition: Summary measures of a distribution<br>The <strong>mean</strong> of $X$,$\mu$ (or $\mathbb{E}(X)$), measures the central tendency of $X$.<br>The second central moment, $\mathbb{E}[(X-\mu)^2]$, is denoted by $\sigma^2$ or $\mathrm{Var}(X)$ and is known as the <strong>variance</strong> of $X$.<br>The square root of $\sigma^2$, $\sigma$, is known as the <strong>standard deviation</strong> of $X$ and has the same unit as $X$. Both $\sigma$ and $\sigma^2$ measure the dispersion(spread) of $X$ about the mean.</li><li>The variance is equal to the second raw moment minus the square of the mean:<script type="math/tex; mode=display">\begin{align*} \mathbb{E}[(X-\mu)^2] &= \mathbb{E}(X^2-2\mu X + \mu^2) \\  &= \mathbb{E}(X^2) - 2\mu\mathbb{E}(X) + \mu^2 \\  &= \mathbb{E}(X^2) - \mu^2 \end{align*}</script></li><li>$\mathrm{Var}(a X + b)=a^2 \mathrm{Var}(X)$ for any constants $a$, $b$ and random variable $X$.</li></ul></li><li>Higher moments<ul><li>Definition: Skewness (third moment)<br>The third central moment provides a measure of the <strong>skewness</strong> (asymmetry) of the distribution. The coefficient of skewness is defined as<script type="math/tex; mode=display">\mathbb{E}[(X-\mu)^3] / \sigma^3</script>It is positive if the distribution is right-skewed, and negative if it is left-skewed.</li><li>Definition: Kurtosis (fourth moment)<br>The fourth central moment provides a measure of the <strong>kurtosis</strong> (tailedness) of the distribution. The coefficient of kurtosis is defined as<script type="math/tex; mode=display">\mathbb{E}[(X-\mu)^4] / \sigma^4</script>A leptokurtic distribution has fat tails (kurtosis &gt; 3), and a platykurtic distribution has thin tails (kurtosis &lt; 3).</li></ul></li><li>Moment-generating functions<br>Definition: Moment-generating function<br>The moment-generating function (mgf) of a random variable $X$ is defined as<script type="math/tex; mode=display">M_X(t) = \mathbb{E}(e^{tX})</script>if it exists, with $t$ the argument of the mgf. It is possible that $M_X(t)$ is finite only on a subset of $\mathbb{R}$.<br>This function is “moment-generating” in the sense that we can obtain moments from it:<script type="math/tex; mode=display">\mathbb{E}(X^n) = \frac{d^n}{dt^n}M_X(t)\bigg\vert_{t=0}</script>From the definition, we obtain that<br>$M_{aX+b}(t) = \mathbb{E}[e^{t(aX+b)}] = e^{bt}\mathbb{E}(e^{atX}) = e^{bt}M_X(at)$ for constants $a,b$ , if $M_X(at)$ exists.</li><li>Moments of functions of random variables<br>For a function $g(X,Y)$ of two variables, the expectation is equal to <script type="math/tex; mode=display">\mathbb{E}[g(X,Y)]=\left\{\begin{array}{ll}\sum_x\sum_y g(x,y)p_{X,Y}(x,y), & \mathrm{if\space discrete;} \\\int_{-\infty}^{\infty}\int_{-\infty}^{\infty} g(x,y)f_{X,Y}(x,y) \mathrm{d}x \mathrm{d}y & \mathrm{if\space continuous.} \\\end{array}\right.</script>Note the following useful properties, where $a,b$ are constants and $g,h$ are (known) functions.<ol><li>$\mathbb{E}[a\cdot g(X) + b \cdot h(Y)] = a\mathbb{E}[g(X)]+b\mathbb{E}[h(Y)]\mathrm{(linearity)}$</li><li>If $X$ and $Y$ are independent, then $\mathbb{E}[g(X)\cdot h(Y)]=\mathbb{E}[g(X)]\cdot \mathbb{E}[h(Y)]$</li><li>If $X$ and $Y$ are independent, then $M_{aX+bY}(t)=M_X(at)M_Y(bt)$</li></ol></li><li><p>Covariance and correlation<br>Definition: Covariance and correlation<br>For random variables $X,Y$ with means $\mu_X,\mu_Y$ and standard deviations $\sigma_X,\sigma_Y$, the <strong>covariance</strong> is defined by</p><script type="math/tex; mode=display">\sigma_{XY} = Cov(X,Y):=\mathbb{E}[(X-\mu_X)(Y-\mu_Y)] = \mathbb{E}(XY) - \mu_X\mu_Y</script><p>The <strong>correlation coefficient</strong> is defined by</p><script type="math/tex; mode=display">\rho_{XY} = Cor(X,Y)\mathrm{\space or\space} Corr(X,Y)=\frac{\sigma_{XY}}{\sigma_X\sigma_Y}</script><p>It can be shown that <script type="math/tex">-1\le \rho_{XY}\le 1</script> for any $X,Y$ such that $\rho_{XY}$ exists.</p><p>Random variables having positive (negative) covariance/correlation coefficient are known as positively (negatively) correlated.</p><p>Some properties of the covariance/correlation of two random variables:</p><ol><li>For independent variables, <script type="math/tex">\sigma_{XY}=\rho_{XY}=0</script>. The reverse is not true!</li><li>$Var(X)=Cov(X,X)$.</li><li>$Cov(X,Y)=Cov(Y,X)$.</li><li>$Cov(aX+b,cY+d)=Cov(aX,cY)=acCov(X,Y)$.</li><li>$Var(aX+bY)=a^2Var(X)+b^2Var(Y)+2abCov(X,Y)$.</li><li>More generally, <script type="math/tex">Var(\sum_{i=1}^n a_iX_i) = \sum_{i=1}^n\sum_{i=1}^n a_ia_jX_iX_j</script>.</li><li>$Cor(aX+b,cY+d)=sign(ac)Cor(X,Y)$,where $sign(ac)=-1$ if $ac\lt 0$ and 1 if $ac\gt 0$.</li></ol></li><li>Conditional expectations<script type="math/tex; mode=display">\mathbb{E}(Y|X=x)=\left\{\begin{array}{ll}\sum_i i\cdot p_{Y|X}(i|X=x), & \mathrm{if\space discrete;} \\\int_{-\infty}^{\infty} t\cdot f_{Y|X}(t|x)\mathrm{d}t & \mathrm{if\space continuous.} \\\end{array}\right.</script>This is known as the conditional mean. The conditional variance can be computed as $\mathbb{E}(Y^2|X=x)-[\mathbb{E}(Y|X=x)]^2$.</li><li>Iterated moments<br>Theorem: Law of total expectation/variance<br>For random variables $X,Y$, we have<br><script type="math/tex">\mathbb{E}(X)=\mathbb{E}[\mathbb{E}(X|Y)]</script>;<br><script type="math/tex">Var(X)=\mathbb{E}[Var(X|Y)]+Var[\mathbb{E}(X|Y)]</script>.</li></ol><h2 id="Some-common-distributions"><a href="#Some-common-distributions" class="headerlink" title="Some common distributions"></a>Some common distributions</h2><h3 id="Discrete-distribution-—-Uniform-a-b"><a href="#Discrete-distribution-—-Uniform-a-b" class="headerlink" title="Discrete distribution — Uniform(a, b)"></a>Discrete distribution — Uniform(a, b)</h3><p>For integers $a$ and $b$ with $a \le b$, the <strong>discrete uniform distribution</strong> puts equal point masses at $a, a + 1, a + 2, \dots , b$.</p><p>pmf: <script type="math/tex">p_X(x) = \frac{1}{b-a+1},\space x\in \{ a,a+1,\dots,b \}</script></p><p>cdf: <script type="math/tex">F_X(x)=\frac{\lfloor x\rfloor-a+1}{b-a+1},\space x\in[a,b]</script></p><p>Mean: <script type="math/tex">\mathbb{E}(X)=\frac{a+b}{2}</script></p><p>Variance: <script type="math/tex">\mathrm{Var}(X)=\frac{(b-a+1)^2-1}{12}</script></p><p>mgf: (omitted)</p><h3 id="Discrete-distribution-—-Bernoulli-p"><a href="#Discrete-distribution-—-Bernoulli-p" class="headerlink" title="Discrete distribution — Bernoulli(p)"></a>Discrete distribution — Bernoulli(p)</h3><p>The <strong>Bernoulli distribution</strong> models the number of successes of a single trial with success probability $p\in [0,1]$</p><p>pmf: <script type="math/tex">pX(x)=p^x(1-p)^{1-x},\space x\in \{0,1\}</script></p><p>cdf: <script type="math/tex">F_X(x)=\left\{  \begin{array}{ll}  0 & x \in (-\infty,0) \\  1-p &  x\in [0,1)\\  1 & x\in [1,\infty)  \end{array}  \right.</script></p><p>Mean: <script type="math/tex">\mathbb{E}(X)=p</script></p><p>Variance: <script type="math/tex">\mathrm{Var}(X)=p(1-p)</script></p><p>mgf: <script type="math/tex">M_X(t)=(1-p)+pe^t,\space t\in\mathbb{R}</script></p><h3 id="Discrete-distribution-—-Binomial-n-p"><a href="#Discrete-distribution-—-Binomial-n-p" class="headerlink" title="Discrete distribution — Binomial(n,p)"></a>Discrete distribution — Binomial(n,p)</h3><p>The Binomial distribution models the number of successes of n independent trials, each with success probability $p \in [0, 1]$.</p><p>pmf: <script type="math/tex">p_X(x)=\binom{n}{x}p^x(1-p)^{n-x},\space x\in \{0,1,\dots,n\}</script></p><p>cdf: (no simple expression)</p><p>Mean: <script type="math/tex">\mathbb{E}(X)=np</script></p><p>Variance: <script type="math/tex">\mathrm{Var}(X)=np(1-p)</script></p><p>mgf: <script type="math/tex">M_X(t)=[(1-p)+pe^t]^n,\space t\in\mathbb{R}</script></p><p>$\binom{n}{x}=n!/[x!(n-x)!]$ is the binomial coefficient.</p><p>If <script type="math/tex">X_1,X_2,\dots,X_n</script> are independent and identically distributed as Bernoulli(p), then the sum <script type="math/tex">\sum_i X_i \sim \text{Binomial}(n,p)</script>.</p><h3 id="Discrete-distribution-—-Poisson-λ"><a href="#Discrete-distribution-—-Poisson-λ" class="headerlink" title="Discrete distribution — Poisson(λ)"></a>Discrete distribution — Poisson(λ)</h3><p>The Poisson distribution arises in two contexts: (1) Number of arrivals (occurrences) in a specific time period; (2) Approximation to<br>the binomial distribution. It has a single parameter $\lambda \gt 0$.</p><p>pmf: <script type="math/tex">p_X(x)=\frac{\lambda^xe^{-\lambda}}{x!},\space x\in \{0,1,2,\dots\}</script></p><p>cdf: (no simple expression)</p><p>Mean: <script type="math/tex">\mathbb{E}(X)=\lambda</script></p><p>Variance: <script type="math/tex">\mathrm{Var}(X)=\lambda</script></p><p>mgf: <script type="math/tex">M_X(t)=e^{\lambda(e^t-1)},\space t\in\mathbb{R}</script></p><p>$\lambda$ is known as the parameter. It can be shown that, if the arrival between any two events (interarrival time) is independently exponentially distributed with mean $1/\lambda$, then the number of arrivals by time 1 follows $\text{Poisson}(\lambda)$.</p><p>If $X_1,X_2,\dots,X_n$ are independent and each has a $\text{Poisson}(\lambda_i)$ distribution (i.e., the rate can be different for each $X_i$), then  the sum $\sum_i X_i\sim\text{Poisson}(\sum_i\lambda_i)$</p><p>If the binomial parameters $n\rightarrow \infty,p\rightarrow 0$ but $ np\rightarrow \lambda $, then $\text{Binomial}(n,p)\rightarrow \text{Poisson}(\lambda)$. The approximation works well if $n\gt 100$ and $np\lt 10$.</p><h3 id="Discrete-distribution-—-NegBin-r-p-amp-Geom-p"><a href="#Discrete-distribution-—-NegBin-r-p-amp-Geom-p" class="headerlink" title="Discrete distribution — NegBin(r, p) &amp; Geom(p)"></a>Discrete distribution — NegBin(r, p) &amp; Geom(p)</h3><p>The <strong>negative binomial distribution</strong> models the number of failures before r successes are achieved, with trials independent of each other and having success probability $p\in(0,1]$</p><p>pmf: <script type="math/tex">p_X(x)=\binom{r+x-1}{x}p^r(1-p)^x,\space x\in \{0,1,2,\dots\}</script>.</p><p>cdf: (no simple expression)</p><p>Mean: <script type="math/tex">\mathbb{E}(X)=r(1-p)/p</script></p><p>Variance: <script type="math/tex">\mathrm{Var}(X)=r(1-p)/p^2</script></p><p>mgf: <script type="math/tex">M_X(t)=[\frac{p}{1-(1-p)e^t}]^r,\space t\lt -\log(1-p)</script></p><p>The special case of $r=1$ is known as the <strong>geometric distribution</strong>.</p><p>If <script type="math/tex">X_1,X_2,\dots,X_r</script> are independent <script type="math/tex">\text{Geometric}(p)</script> random variables, then <script type="math/tex">\sum_{i=1}^r X_i\sim \text{NegBin}(r,p)</script></p><p>The geometric distribution is the only discrete distribution that is <strong>memoryless</strong>.</p><h3 id="Continuous-distribution-—-Uniform-a-b"><a href="#Continuous-distribution-—-Uniform-a-b" class="headerlink" title="Continuous distribution — Uniform(a, b)"></a>Continuous distribution — Uniform(a, b)</h3><p>For real numbers $a$ and $b$ with $a\lt b$, the <strong>continuous uniform distribution</strong> has a constant density over $[a,b]$.</p><p>pdf: <script type="math/tex">f_X(x)=\frac{1}{b-a},\space x\in [a,b]</script></p><p>cdf: <script type="math/tex">F_X(x)=\frac{x-a}{b-a},\space x\in[a,b]</script></p><p>Mean: <script type="math/tex">\mathbb{E}(X)=\frac{a+b}{2}</script></p><p>Variance: <script type="math/tex">\mathrm{Var}(X)=\frac{(b-a)^2}{12}</script></p><p>mgf: <script type="math/tex">M_X{t}=\frac{e^{bt}-e^{at}}{(b-a)t},\space t\ne 0; M_X(0)=1</script></p><h3 id="Continuous-distribution-—-Beta-α-β"><a href="#Continuous-distribution-—-Beta-α-β" class="headerlink" title="Continuous distribution — Beta(α, β)"></a>Continuous distribution — Beta(α, β)</h3><p>The <strong>beta distribution</strong> generalizes the uniform distribution on the [0, 1] interval. For parameters $\alpha,\beta\gt 0$, it has the fowwing quantities:</p><p>pdf: <script type="math/tex">f_X(x)=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1},\space x\in[0,1]</script></p><p>cdf: (no simple expression)</p><p>Mean: <script type="math/tex">\mathbb{E}(X)=\frac{\alpha}{\alpha+\beta}</script></p><p>Variance: <script type="math/tex">\mathrm{Var}(X)=\frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}</script></p><p>mgf: (no simple expression)</p><p>$\Gamma(t)=\int_0^{\infty}x^{t-1}e^{-x}\mathrm{d}x$ is the gamma function.<br>Note that $\Gamma(t)=(t-1)\Gamma(t-1)$ and $\Gamma(n)=(n-1)!$ for integral $n$.</p><p>The $\text{Beta}(1, 1)$ and $\text{Uniform}(0, 1)$ distributions are identical.</p><p>A beta distribution is left-skewed if $\alpha\gt\beta$ (large mean) and right-skewed if $\alpha\lt\beta$ (small mean).</p><p>If $X_1, \dots , X_n$ are independent $\text{Uniform}(0, 1)$ random variables, then the $k$th order statistic (i.e., $k$th smallest number among the $X_i$’s) has a $\text{Beta}(k, n + 1 − k)$ distribution.</p><h3 id="Continuous-distribution-Gamma-α-β-amp-Exponential-β"><a href="#Continuous-distribution-Gamma-α-β-amp-Exponential-β" class="headerlink" title="Continuous distribution - Gamma(α, β) &amp; Exponential(β)"></a>Continuous distribution - Gamma(α, β) &amp; Exponential(β)</h3><p>The <strong>gamma distribution</strong> has connections with the sum of interarrival times mentioned above for the Poisson distribution.</p><p>For parameters $\alpha,\beta\gt 0$,</p><p>pdf: <script type="math/tex">f_X(x)=\frac{\beta^{\alpha}}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x},\space x\in [0,\infty)</script></p><p>cdf: (no simple expression)</p><p>Mean: <script type="math/tex">\mathbb{E}(X)=\alpha / \beta</script></p><p>Variance <script type="math/tex">\mathrm{Var}(X)=\alpha / \beta^2</script></p><p>mgf: <script type="math/tex">M_X{t}=(\frac{\beta}{\beta-t})^{\alpha},\space t\lt \beta</script></p><p>$\alpha$ is known as the <em>shape</em> parameter and $\beta$ the <em>rate</em> parameter.</p><p>The special case of $\alpha=1$ is known as the <strong>exponential distribution</strong>. The corresponding quantities are:</p><p>pdf: <script type="math/tex">f_X(x)=\beta e^{-\beta x},\space x\in [0,\infty)</script></p><p>cdf: <script type="math/tex">F_X(x)=1- e^{-\beta x},\space x\in[0,\infty)</script></p><p>Mean: <script type="math/tex">\mathbb{E}(X)=1/ \beta</script></p><p>Variance <script type="math/tex">\mathrm{Var}(X)=1/ \beta^2</script></p><p>mgf: <script type="math/tex">M_X{t}=\frac{\beta}{\beta-t},\space t\lt \beta</script></p><p>If <script type="math/tex">X_1,\dots,X_n</script> are independent <script type="math/tex">\mathrm{Exponential}(\beta)</script> random variables, then $\sum_{i=1}^n X_i \sim\mathrm{Gamma}(n,\beta)$</p><p>If <script type="math/tex">X_1,\dots,X_n</script> are independent <script type="math/tex">\mathrm{Gamma}(\alpha_i,\beta)</script> random variables, then $\sum_i X_i \sim\mathrm{Gamma}(\sum_i \alpha_i,\beta)$</p><p>If <script type="math/tex">X\sim \mathrm{Gamma}(\alpha,\beta)</script>, then <script type="math/tex">cX\sim \mathrm{Gamma}(\alpha,\beta/c)</script> for any constant $c\gt 0$</p><p>The exponential distribution is the only continuous distribution that is <strong>memoryless</strong>, i.e., the distribution of $X-m$ given $X\ge m$ is the same exponential.</p><h3 id="Continuous-distribution-Chi-squared-nu"><a href="#Continuous-distribution-Chi-squared-nu" class="headerlink" title="Continuous distribution - Chi-squared($\nu$)"></a>Continuous distribution - Chi-squared($\nu$)</h3><p>The <strong>chi-squared</strong>(<script type="math/tex">\chi^2</script>) <strong>distribution</strong> has a single parameter $\nu$, known as the <strong>degree-of-freedom</strong> parameter.</p><p>pdf: <script type="math/tex">f_X(x)=\frac{1}{2^{\nu/2}\Gamma(\nu/2)}x^{\nu/2-1}e^{-x/2},\space x\in[0,\infty)</script></p><p>cdf: (no simple expression)</p><p>Mean: <script type="math/tex">\mathbb{E}(X)=\nu</script></p><p>Variance: <script type="math/tex">\mathrm{Var}(X)=2\nu</script></p><p>mgf: <script type="math/tex">M_X(t)=(\frac{1}{1-2t})^{\nu/2},\space t\lt\frac{1}{2}</script></p><p>The <script type="math/tex">\chi^2(\nu)</script> distribution is equvalent to the $\mathrm{Gamma}(\nu/2,1/2)$ distribution.</p><p>If <script type="math/tex">X_1,\dots,X_n</script> are indenenpent <script type="math/tex">\mathrm{Normal}(0,1)</script> random variables, then $\sum_{i=1}^n X_i^2 \sim \chi^2(n)$.</p><p>If <script type="math/tex">X_1,\dots,X_n</script> are indenenpent <script type="math/tex">\chi^2(\nu_i)</script> random variables, then $\sum_i X_i^2 \sim \chi^2(\sum_i\nu_i)$. This follows from the same property of the gamma distribution.</p><h3 id="Continuous-distribution-Normal-mu-sigma-2"><a href="#Continuous-distribution-Normal-mu-sigma-2" class="headerlink" title="Continuous distribution - Normal($\mu$,$\sigma^2$)"></a>Continuous distribution - Normal($\mu$,$\sigma^2$)</h3><p>The <strong>normal distribution</strong> (or Gaussian distribution) is the cornerstone of statistics. For parameters $\mu$ and $\sigma^2\gt 0$, it has the following quantities:</p><p>pdf: <script type="math/tex">f_X(x)=\frac{1}{\sqrt{2\pi\sigma^2}}exp{-\frac{(x-\mu)^2}{2\sigma^2}},\space x\in\mathbb{R}</script></p><p>cdf: (no simple expression)</p><p>Mean: <script type="math/tex">\mathbb{E}(X)=\mu</script></p><p>Variance: <script type="math/tex">\mathrm{Var}(X)=\sigma^2</script></p><p>mgf: <script type="math/tex">M_X(t)=exp\{\mu t+\frac{1}{2}\sigma^2t^2\}</script></p><p>The Normal(0,1) or N(0,1) distribution is known as the <strong>standard distrubution</strong>. Its cdf is often denoted by the Greek letter $\Phi$.</p><p>If <script type="math/tex">X\sim N(\mu,\sigma^2)</script>, then <script type="math/tex">(X-\mu)/\sigma\sim N(0,1)</script>. This is known as standardization.</p><p>If <script type="math/tex">X\sim N(\mu,\sigma^2)</script>, then <script type="math/tex">aX+b\sim N(a\mu+b,a^2\sigma^2)</script> for any constants <script type="math/tex">a,b</script>.</p><p>If $X_1,\dots,X_n$ are independent $N(\mu_i,\sigma_i^2)$ random variables, then $\sum_i X_i\sim N(\sum_i\mu_i,\sum_i\sigma_i^2)$.</p><p>Normal approximation to the binomial: Binomial(n,p) can be approximated by N(np,np(1-p)) when n is large. In fact, as $n\rightarrow \infty$, we have</p><script type="math/tex; mode=display">\frac{Y-np}{\sqrt{np(1-p)}}\xrightarrow{\text{d}} N(0,1)</script><p>Several other distributions also approach the normal in the limit.</p><ul><li>Poisson($\lambda$) can be approximated by N($\lambda$,$\lambda$) if $\lambda$ is large.</li><li>Gamma($\alpha$,$\beta$) can be approximated by $N(\alpha/\beta,\alpha/\beta^2)$ if $\alpha$ is large.</li><li>NegBin(r,p) can be approximated by $N(r(1-p)/p,r(1-p)/p^2)$ if r is large.</li></ul><h3 id="Continuous-distribution-honourable-mention"><a href="#Continuous-distribution-honourable-mention" class="headerlink" title="Continuous distribution - honourable mention"></a>Continuous distribution - honourable mention</h3><p>In statistics you will often hear the <strong>t</strong> and <strong>F</strong>  distributions. They are the results of combining independent variables mentioned above, for example: </p><script type="math/tex; mode=display">T=\frac{Z}{\sqrt{W/\nu}}</script><p>gives a t-distributed random variable, where $Z\sim N(0,1),W\sim \chi^2(\nu)$ and $Z\perp\kern-5pt\perp W$, and</p><script type="math/tex; mode=display">F=\frac{X_1/\nu_1}{X_2/\nu_2}</script><p>is distributed, where $X_1\sim\chi^2(\nu_1)$,$X_2\sim\chi^2(\nu_2)$ and $X_1\perp\kern-5pt\perp X_2$</p><h1 id="Sampling-and-Estimation"><a href="#Sampling-and-Estimation" class="headerlink" title="Sampling and Estimation"></a>Sampling and Estimation</h1><h2 id="Sampling-distributions"><a href="#Sampling-distributions" class="headerlink" title="Sampling distributions"></a>Sampling distributions</h2><ul><li>A <strong>population</strong> is the complete set of items or events of interest. A <strong>sample</strong> is a subset of outcomes collected.</li><li>A <strong>random sample</strong> is a sequence of i.i.d. random variables from a<br>population distribution. Let <script type="math/tex">\{X_1, X_2, \dots , X_n \}</script> denote a random<br>sample of size n.</li><li>For a random sample  <script type="math/tex">\{X_1, X_2, \dots , X_n\}</script>, the sample mean $\bar{X}$ and sample variance $S^2$ are respectively defined by<script type="math/tex; mode=display">\bar{X}=\frac{1}{n}\sum_{i=1}^n X_i, S^2=\frac{1}{n-1}\sum_{i=1}^n(X_i-\bar{X})^2</script></li><li>For a random sample <script type="math/tex">\{X_1, X_2, \dots , X_n\}</script> from a population with mean $\mu$ and variance $\sigma^2$,<script type="math/tex; mode=display">\mathbb{E}(\bar{X})=\mu, \mathrm{Var}(\bar{X})=\frac{\sigma^2}{n}</script></li><li>The standard deviation (SD) of $\bar{X}$ , $\sigma/\sqrt{n}$, is known as the <strong>standard error</strong> (SE).</li><li>The SE is smaller with larger $n$ — this is intuitive as a larger sample will allow us to estimate $\mu$ more precisely.</li><li><p>For a random sample <script type="math/tex">\{X_1, X_2, \dots , X_n\}</script> from a population with mean $\mu$ and variance $\sigma^2$,</p><script type="math/tex; mode=display">\mathbb{E}(S^2)=\sigma^2</script><h2 id="Sampling-distributions-for-the-normal-distribution"><a href="#Sampling-distributions-for-the-normal-distribution" class="headerlink" title="Sampling distributions for the normal distribution"></a>Sampling distributions for the normal distribution</h2></li><li><p>For a random sample <script type="math/tex">\{X_1, X_2, \dots , X_n\}</script> from the $N(\mu,\sigma^2)$ distribution,</p><ol><li>$\bar{X}\sim N(\mu,\sigma^2/n)$</li><li>$(n-1)S^2/\sigma^2\sim \chi^2(n-1)$</li><li>$\bar{X}$ is independent of $S^2$</li></ol></li><li>If $\bar{X}$ and $S^2$ are the size-n sample mean and variance of the $N(\mu,\sigma^2)$ distribution, then<script type="math/tex; mode=display">\frac{\bar{X}-\mu}{S/\sqrt{n}}</script>has the t-distribution with n-1 degrees of freedom, denoted as $t(n-1)$(or $t_{n-1}$)</li><li>Properties of the $t(\nu)$ distribution:<ul><li>pdf: <script type="math/tex; mode=display">f_X(x)=\frac{\Gamma[(1+\nu)/2]}{\sqrt{\nu\pi}\Gamma(\nu/2)}(1+\frac{x^2}{\nu})^{-\frac{1+\nu}{2}},x\in \mathbb{R}</script></li><li>cdf: (no simple expression)</li><li>Mean: $\mathbb{E}(X)=0$ if $\nu\gt 1$</li><li>Variance: $Var(X)=\frac{\nu}{\nu-2}$ if $\nu\gt 2$</li><li>mgf: (undefined)</li></ul></li><li><p>The $100(1 − \alpha)\%$ <strong>confidence interval</strong> (CI) for $\mu$ based on a random<br>sample from a normal distribution is</p><script type="math/tex; mode=display">[\bar{x}\pm t_{n-1,\alpha/2} \cdot \frac{s}{\sqrt{n}}]</script><p>where $\bar{x}$ is the (observed) sample mean, s is the (observed) sample SD, $n$ is the sample size and <script type="math/tex">t_{n-1,\alpha/2}</script> is defined as the value such that $\mathbb{P}(T\gt t_{n-1,\alpha/2})=\alpha/2$ for $T\sim t(n-1)$ (i.e., the $(1-\alpha/2)$ quantile of $T$) </p><h2 id="Large-sample-theory"><a href="#Large-sample-theory" class="headerlink" title="Large sample theory"></a>Large sample theory</h2></li><li><p>Weak law of large numbers(WLLN)<br>For a random sample <script type="math/tex">\{X_1, X_2, \dots , X_n\}</script> with finite (population) mean $\mu$,let $\bar{X_n}=\sum{i=1}^n X_i/n$ be the sample mean. The <strong>weak law of large numbers</strong> suggests that</p><script type="math/tex; mode=display">\lim_{n\rightarrow\infty}\mathbb{P}(|\bar{X_n}-\mu|\gt\epsilon)=0</script><p>for any positive $\epsilon$. In other words, $\bar{X_n}$ converges in probability to $\mu$, written as $\bar{X_n}\overset{P}{\rightarrow}X$</p></li><li>Strong law of large numbers(SLLN)<br>For a random sample <script type="math/tex">\{X_1, X_2, \dots , X_n\}</script> with finite (population) mean $\mu$,let $\bar{X_n}=\sum{i=1}^n X_i/n$ be the sample mean. The <strong>strong law of large numbers</strong> suggests that<script type="math/tex; mode=display">\mathbb{P}(\lim_{n\rightarrow\infty}\bar{X_n}=\mu)=1</script>In other words, $\bar{X_n}$ converges almost surely to $\mu$, written as $\bar{X_n}\overset{a.s.}{\rightarrow}X$</li><li><p>Central limit theorem<br>For a random sample <script type="math/tex">\{X_1, X_2, \dots , X_n\}</script> with finite (population) mean $\mu$ and variace $\sigma^2$,let <script type="math/tex">\bar{X_n}=\sum_{i=1}^n X_i/n</script> be the sample mean. The <strong>central limit theorem</strong> suggests that</p><script type="math/tex; mode=display">\lim_{n\rightarrow\infty}\mathbb{P}(\frac{\bar{X_n}-\mu}{\sigma/\sqrt{n}}\le x)=\Phi(x)</script><p>pointwise. In other words, $(\bar{X_n}-\mu)/(\sigma/\sqrt{n})$ converges in distribution to a standard normal random variable, written as $(\bar{X_n}-\mu)/(\sigma/\sqrt{n})\overset{d}{\rightarrow}N(0,1)$</p><h2 id="Point-estimation-properties-of-estimators"><a href="#Point-estimation-properties-of-estimators" class="headerlink" title="Point estimation - properties of estimators"></a>Point estimation - properties of estimators</h2></li><li><p>Let the parameter be denoted as $\theta$. The <strong>point estimator</strong> of $\theta$, usually denoted as $\hat{\theta_n}$ where $n$ is the sample size, is a sample statistic used to estimate $\theta$. The realized value of $\hat{\theta_n}$ is called the <strong>point estimate</strong>.</p></li><li>Bias<br>The <strong>bias</strong> of an estimator $\hat{\theta_n}$ is given by<script type="math/tex; mode=display">Bias(\hat{\theta_n})=\mathbb{E}(\hat{\theta_n})-\theta</script>If the bias is zero for every possible value of $\theta$, the estimator is <strong>unbiased</strong>.<br>If the bias is not zero but tend to zero as $n\rightarrow \infty$, the estimator is <strong>asymptotically unbiased</strong>.<br>An estimator tend to underestimate the true value if $\mathbb{E}(\hat{\theta_n})\lt\theta$ and overestimate the true value if $\mathbb{E}(\hat{\theta_n})\gt\theta$</li><li>Mean squared error<br>The <strong>mean squared error</strong>(MSE) of an estimator $\hat{\theta_n}$ is given by<script type="math/tex; mode=display">MSE(\hat{\theta_n})=\mathbb{E}[(\hat{\theta_n}-\theta)^2]=Var(\hat{\theta_n})+[Bias(\hat{\theta_n})]^2</script>To achieve a low MSE, an estimator needs to be accurate (close to the true value) and precise (with little variability).<br>For an unbiased estimator, the MSE is equal to $Var(\hat{\theta_n})$</li><li>Efficiency<br>For two unbiased estimators <script type="math/tex">\hat{\theta_{1,n}}</script> and <script type="math/tex">\hat{\theta_{2,n}}</script> of <script type="math/tex">\theta</script>, <script type="math/tex">\hat{\theta_{1,n}}</script> is said to be <strong>more efficient</strong> than <script type="math/tex">\hat{\theta_{2,n}}</script> if<script type="math/tex; mode=display">Var(\hat{\theta_{1,n}})\le Var(\hat{\theta_{2,n}})</script>for all possible values of the true parameter $\theta$.<br>If either estimator is biased, it is better to make comparisons via the MSE since it also takes into account the magnitude of the bias.<br>An unbiased estimator that has the smallest variance among all other unbiased estimators for all $\theta$ is known as the <strong>uniformly minimum variance unbiased estimator</strong>, or UMVUE.</li><li>Consistency<br>An estimator $\hat{\theta_n}$ is consistent for $\theta$, if for every $\epsilon\gt0$ we have<script type="math/tex; mode=display">\lim_{n\rightarrow\infty}\mathbb{P}(|\hat{\theta_n}-\theta|<\epsilon)=1</script>In other words, $\hat{\theta_n}\overset{p}{\rightarrow}\theta$ as $n\rightarrow\infty$ if it is consistent.<br>This definition is often hard to check. A useful workaround(sufficient but no necessary condition) is that if <script type="math/tex; mode=display">\lim_{n\rightarrow\infty}MSE(\hat{\theta_n})=0</script>then $\hat{\theta_n}$ is consistent for $\theta$.<h2 id="Point-estimation-methods"><a href="#Point-estimation-methods" class="headerlink" title="Point estimation -methods"></a>Point estimation -methods</h2></li><li>The <strong>method of moments</strong> estimates parameters by equating the sample raw moments to the raw moments of the target distribution. They are defined as:<br>Sample <script type="math/tex">r</script>th raw mooment: <script type="math/tex">m_r:=\frac{1}{n}\sum_{i=1}^n X_i^r</script><br><script type="math/tex">r</script>th raw moment of the distribution: $\mathbb{E}(X^r)$</li><li><p>Method of maximum likelihood<br>The method of <strong>maximum likelihood</strong> considers the pdf/pmf as a likelihood function that is maximized. Some definitions are in order:<br>Suppose random variables $X_1,\dots,X_n$ have joint pdf or pmf $f_X(x_1,\dots,x_n;\theta)$, where $\theta$ is a collection of parameters. The <strong>likelihood function</strong> L is simply $f_X(x_1,\dots,x_n;\theta)$, but viewing it as a function of $\theta$ with $x_1,\dots,x_n$ fixed at their observed values. That is,</p><script type="math/tex; mode=display">L(\theta;x_1,\dots,x_n)=f_X(x_1,\dots,x_n;\theta)</script><p>The log-likelihood function <script type="math/tex">\ell</script> is the (natural) logarithm of <script type="math/tex">L</script>, i.e.,<script type="math/tex">\ell(\theta;x_1,\dots,x_n)=\log L(\theta;x_1,\dots,x_n)=\log f_X(x_1,\dots,x_n;\theta)</script><br>Note that <script type="math/tex">X_1,\dots,X_n</script> need not be independent.<br>The <strong>maximun likelihood estimator</strong>(MLE) $\hat{\theta_{ML}}$ of a parameter $\theta$ is the value of $\theta$ that maximizes the likelikood (or log-likelihood) function, that is,</p><script type="math/tex; mode=display">\hat{\theta_{ML}}=\arg\max_{\theta}L(\theta;x_1,\dots,x_n)</script><p>If <script type="math/tex">\hat{\theta_{ML}}</script> is the MLE of <script type="math/tex">\theta</script>, then <script type="math/tex">g(\hat{\theta_{ML}})</script> is the MLE of <script type="math/tex">g(\theta)</script>, a function of <script type="math/tex">\theta</script>.</p><h2 id="Interval-estimation"><a href="#Interval-estimation" class="headerlink" title="Interval estimation"></a>Interval estimation</h2></li><li><p>For a random sample <script type="math/tex">\{X_1, X_2, \dots , X_n\}</script> used to estimate an unknown parameter $\theta$, let $L(X)$ and $U(X)$ be some functions of the random sample with</p><script type="math/tex; mode=display">\mathbb{P}\{L(X)\le\theta\le U(X)\}=1-\alpha</script><p>where $1-\alpha$ is typically a high probability. The interval $[L(X),U(X)]$ is known as a $100(1-\alpha)\%$ <strong>confidence interval</strong>(CI) for the parameter $\theta$.</p></li><li>The following is a general recipe for finding CI’s:<ol><li>Establish a <strong>pivotal quantity</strong>. A pivotal quantity is a function of the random sample and model parameters that has a distribution not involving $\theta$, written as $V(X\theta)$.</li><li>Find some constants a,b such that <script type="math/tex; mode=display">\mathbb{P}(a\le V(X,\theta)\le b)=1-\alpha</script>Because the distribution of $V(X,\theta)$ does not depend on $\theta$, the constants a and b will also be free of $\theta$.</li><li>Solve $a\le V(X,\theta)$ and $b\gt V(X,\theta)$ for $\theta$. This will give a lower limit $L(X)$ and an upper limit $U(X)$ such that<script type="math/tex; mode=display">\mathbb{P}{L(X)\le\theta\le U(X)}=1-\alpha</script>The required CI is given by $[L(X),U(X)]$.</li></ol></li><li>Interval estimation for means - $N(\mu,\sigma^2)$<br>The pivotal quantity $\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\sim N(0,1)$<br>The CI for the population mean is given by $[\bar{X}\pm z_{\alpha/2}\frac{\sigma}{\sqrt{n}}]$</li><li>Interval estimation for means - $N(\mu,?)$<br>The pivotal quantity $\frac{\bar{X}-\mu}{S/\sqrt{n}}\sim t(n-1)$<br>The CI for the population mean is given by $[\bar{X}\pm t_{n-1,\alpha/2}\frac{S}{\sqrt{n}}]$</li><li>Interval estimation for means - <script type="math/tex">N(\mu_1,\sigma_1^2)</script> vs <script type="math/tex">N(\mu_2,\sigma_2^2)</script><br>The pivotal quantity is <script type="math/tex">\frac{(\bar{X}-\bar{Y})-(\mu_1-\mu_2)}{\sqrt{\sigma_1^2/m+\sigma_2^2/n}}\sim N(0,1)</script><br>The CI for the difference in means is given by <script type="math/tex">(\bar{X}-\bar{Y})\pm z_{\alpha/2}\sqrt{\sigma_1^2/m+\sigma_2^2/n}</script></li><li>Interval estimation for means - <script type="math/tex">N(\mu_1,?)</script> vs <script type="math/tex">N(\mu_2,?)</script><br>The pivotal quantity is <script type="math/tex; mode=display">\frac{(\bar{X}-\bar{Y})-(\mu_1-\mu_2)}{\sqrt{S_p^2/m+S_p^2/n}}\sim t(m+n-2)</script>where <script type="math/tex">s_p^2=\frac{(m-1)S_1^2+(n-1)S_2^2}{m+n-2}</script><br>The CI for the difference in means is given by <script type="math/tex">(\bar{X}-\bar{Y})\pm t_{m+n-2,\alpha/2}\sqrt{S_p^2/m+S_p^2/n}</script></li><li>Interval estimation for means - <script type="math/tex">N(\mu_1,?_1)</script> vs <script type="math/tex">N(\mu_2,?_2)</script><br>The pivotal quantity is <script type="math/tex; mode=display">\frac{(\bar{X}-\bar{Y})-(\mu_1-\mu_2)}{\sqrt{S_1^2/m+S_2^2/n}}\overset{\cdot}\sim t(\nu)</script>The number of degrees of freedom is<script type="math/tex; mode=display">\nu=\frac{(S_1^2/m+S_2^2/n)^2}{\frac{S_1^4}{m^2(m-1)}+\frac{S_2^4}{n^2(n-1)}}</script>The CI for the difference in means is given by <script type="math/tex">(\bar{X}-\bar{Y})\pm t_{\nu,\alpha/2}\sqrt{S_1^2/m+S_2^2/n}</script></li><li>Interval estimation for variances - N(?,?)<br>The pivotal quantity is <script type="math/tex">\frac{(n-1)S^2}{\sigma^2}\sim \chi^2(n-1)</script><br>The CI for the population variance is given by <script type="math/tex">[\frac{(n-1)S^2}{\chi^2_{n-1,\alpha/2}},\frac{(n-1)S^2}{\chi^2_{n-1,1-\alpha/2}}]</script></li><li>Interval estimation for variances - <script type="math/tex">N(?,?_1)</script> vs <script type="math/tex">N(?,?_2)</script><br>The pivotal quantity is <script type="math/tex; mode=display">\frac{[(m-1)S_1^2/\sigma_1^2]/(m-1)}{[(n-1)S_2^2/\sigma_2^2]/(n-1)}=\frac{S_1^2/\sigma_1^2}{S_2^2/\sigma_2^2}\sim F_{m-1,n-1}</script>The CI for the ratio of variances <script type="math/tex">\sigma_1^2/\sigma_2^2</script> is given by<script type="math/tex; mode=display">[\frac{1}{F_{m-1,n-1,\alpha/2}}\frac{S_1^2}{S_2^2},F_{n-1,m-1,\alpha/2}\frac{S_1^2}{S_2^2}]</script><h1 id="Hypothesis-Testing"><a href="#Hypothesis-Testing" class="headerlink" title="Hypothesis Testing"></a>Hypothesis Testing</h1></li></ul><h2 id="Introduction-to-hypothesis-testing"><a href="#Introduction-to-hypothesis-testing" class="headerlink" title="Introduction to hypothesis testing"></a>Introduction to hypothesis testing</h2><ul><li>In statistics, a <strong>hypothesis test</strong> makes a decision between two mutually exclusive statements about the population, known as <strong>hypotheses</strong>.</li><li>The <strong>null hypothesis</strong>, denoted as $H_0$, is a statement that has an established standing or the “standard” that is being put to the test.</li><li>The <strong>alternative hypothesis</strong>, denoted as <script type="math/tex">H_1</script> or <script type="math/tex">H_a</script>, is a statement that challenges the null hypothesis.</li><li>A <strong>simple hypothesis</strong> is one in which the hypothesis statement completely determines a single distribution. Otherwise, it is known as a <strong>composite hypothesis</strong>.</li><li>A <strong>test statistic</strong> is a function of the observed data that is used to construct the condition of a hypothesis test, based on which a decision is made.</li><li>The <strong>rejection</strong> (or critical) <strong>region</strong> is the range of values of the test statistic that, if observed, will lead to the rejection of <script type="math/tex">H_0</script> (and acceptance of <script type="math/tex">H_1</script>).</li><li>The <strong>critical value</strong>(s) demarcates the rejection region.</li><li>The probability of making a type I error, <script type="math/tex">P(\mathrm{reject}\quad H_0 | H_0 \mathrm{\quad is\quad true})</script>, is the <strong>type I error rate</strong> (<script type="math/tex">\alpha</script>); it is also known as the <strong>significance level</strong>.</li><li>The probability of making a type II error, <script type="math/tex">P(\mathrm{accept}\quad H_0 | H_1 \mathrm{\quad is\quad true})</script>, is the <strong>type II error rate</strong> (<script type="math/tex">\beta</script>). One minus this probability gives the <strong>power</strong> of the test.</li><li>The power function of a statistical test gives the probability of rejecting <script type="math/tex">H_0</script> as a function of the true parameter value:<script type="math/tex; mode=display">\pi(\theta)=\mathbb{P}(\mathrm{reject} H_0 \mid \theta)</script></li><li>Note that if <script type="math/tex">\theta \in \Theta_0</script>, the parameter space of <script type="math/tex">H_0</script>, then <script type="math/tex">\pi(\theta)=\mathbb{P}(\mathrm{reject} H_0 \mid \theta)</script> gives the type I error rate.<br>If <script type="math/tex">H_0</script> is a composite hypothesis, then we define the <strong>size</strong> of the test as the <em>maximum</em> possible value of <script type="math/tex">\pi(\theta)</script> for all <script type="math/tex">\theta \in \Theta_0</script>.<br>A test has significance level <script type="math/tex">\alpha</script> if its size is at most <script type="math/tex">\alpha</script>. The significance level and size are equal in many cases.<br>The <strong>power</strong> of a test is the probability of <em>not</em> making a type II error.When <script type="math/tex">H_1</script> is composite, the power at <script type="math/tex">\theta = \theta_1</script> is simply <script type="math/tex">\pi(\theta_1)</script>.</li><li>The <strong>p-value</strong> of a statistical test is the probability of observing a value of the test statistic at least as inconsistent as implied by <script type="math/tex">H_0</script>, if <script type="math/tex">H_0</script> is true. The test rejects <script type="math/tex">H_0</script> if the p-value is less than the significance level.</li></ul><p>General steps in hypothesis testing</p><ol><li>Formulate a statistical model (distribution if parametric).</li><li>Specify the null and alternative hypotheses.</li><li>Determine a test statistic <script type="math/tex">T</script>. It is typically one with a nice distribution under <script type="math/tex">H_0</script>, so that the significance level can be easily obtained.</li><li>Determine the significance level <script type="math/tex">\alpha</script>.</li><li>Collect data and calculate the test statistic. (Note: You <strong>must</strong> specify the significance level prior to data analysis — no cheating!)</li><li>[<strong>Rejection region approach</strong>] Find the rejection region of <script type="math/tex">T</script> that corresponds to the selected <script type="math/tex">\alpha</script>.<br>[<strong>p-value approach</strong>] Calculate the p-value corresponding to the observed test statistic.</li><li>If the observed test statistic is in the rejection region (or the p-value is less than <script type="math/tex">\alpha</script>), you reject <script type="math/tex">H_0</script> and accept <script type="math/tex">H_1</script>. Otherwise you do not reject <script type="math/tex">H_0</script>.</li></ol><h2 id="Duality-between-hypothesis-tests-and-confidence-intervals"><a href="#Duality-between-hypothesis-tests-and-confidence-intervals" class="headerlink" title="Duality between hypothesis tests and confidence intervals"></a>Duality between hypothesis tests and confidence intervals</h2><p><strong>The CI is the set of</strong> <script type="math/tex">\mu_0</script> <strong>under which</strong> <script type="math/tex">H_0</script> <strong>is not rejected</strong>.<br>Equivalently, if the hypothesized <script type="math/tex">\mu_0</script> is not sufficiently far away from <script type="math/tex">\bar{X}</script> in the sense that it lies in the CI, the test will not reject <script type="math/tex">H_0</script>.<br>This is known as the duality between hypothesis tests and CI’s.</p>]]></content>
    
    
    <summary type="html">Personal notes for HKU MDASC 2024fall preparatory course STAT_PROB_2024</summary>
    
    
    
    <category term="HKU Course Notes" scheme="https://shuqian8421.github.io/categories/HKU-Course-Notes/"/>
    
    
  </entry>
  
  <entry>
    <title>一文读懂LaTeX安装（使用TeX Live+Visual Studio Code插件）</title>
    <link href="https://shuqian8421.github.io/posts/50991/"/>
    <id>https://shuqian8421.github.io/posts/50991/</id>
    <published>2024-08-11T16:00:00.000Z</published>
    <updated>2025-02-12T10:38:08.580Z</updated>
    
    <content type="html"><![CDATA[<div class="tabs" id="head"><ul class="nav-tabs no-default"><button type="button" class="tab " data-href="head-1">动机</button><button type="button" class="tab " data-href="head-2">参考</button></ul><div class="tab-contents"><div class="tab-item-content" id="head-1"><p>之前一直用的MiKTeX+TexMaker组合，后来发现MiKTeX在linux下居然不顶用。本着能适配多平台就适配多平台的原则，怎么说平台也要多多益善，更何况还听说MiKTex有时候包更新不及时呢。</p></div><div class="tab-item-content" id="head-2"><div class="tag link"><a class="link-card" title="LaTex 安装和使用" href="https://zhuanlan.zhihu.com/p/693688337"><div class="left"><img src="/img/website_favicon.png"/></div><div class="right"><p class="text">LaTex 安装和使用</p><p class="url">https://zhuanlan.zhihu.com/p/693688337</p></div></a></div></div></div><div class="tab-to-top"><button type="button" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div><div class="note info flat"><p>这篇文章适用于帮助LaTeX新人快速上手安装和使用，不会对LaTeX的工作流程做深入的研究。</p></div><h1 id="LaTeX简介"><a href="#LaTeX简介" class="headerlink" title="LaTeX简介"></a>LaTeX简介</h1><h2 id="介绍LaTeX"><a href="#介绍LaTeX" class="headerlink" title="介绍LaTeX"></a>介绍LaTeX</h2><p>LaTeX是一种排版系统，适用于排版印刷品。对于个人而言，LaTeX很适合用于编写笔记、含有数学公式和图表的论文、幻灯片等等。</p><p>LaTeX在不同的硬件和操作系统上有不同的实现版本，比如Tex Live、MikTeX等。通常来说，这些实现版本都会自带前端的编辑器，但是比较简陋。所以对于对编写界面颇有美观实用要求的很多人，都选择另外安装好看实用的前端工具软件，比如Visual Studio Code(LaTeX Workshop插件)、TexMaker等等。</p><h2 id="选择合适的软件"><a href="#选择合适的软件" class="headerlink" title="选择合适的软件"></a>选择合适的软件</h2><p>看得出来，实现版本和前端界面有不同的组合。每个软件各有优劣，长久以来大家对于“使用LaTeX该用哪些软件最好”的议题莫衷一是。本教程提出一些常见软件的优缺点，读者可根据自身需求进行判断或参阅其他教程。</p><h3 id="LaTeX实现版本"><a href="#LaTeX实现版本" class="headerlink" title="LaTeX实现版本"></a>LaTeX实现版本</h3><p>我们安装LaTeX实现版本的目的是能够把我们编写的LaTeX指令文本最终编译成pdf文档。</p><ol><li>TeX Live<ul><li>优点：<ul><li>由TeX User Group维护，官方可靠有保障</li><li>适配Windows和Unix-based平台（比如Linux），多平台适配</li></ul></li><li>缺点：<ul><li>占用空间比较大，下载了所有的包</li><li>中文支持不友好，如果安装路径有中文的话会很麻烦</li></ul></li></ul></li><li>MiKTex<ul><li>优点：<ul><li>安装简单</li></ul></li><li>缺点：<ul><li>软件由个人维护，部分包更新可能不及时</li></ul></li></ul></li></ol><h3 id="前端编辑工具"><a href="#前端编辑工具" class="headerlink" title="前端编辑工具"></a>前端编辑工具</h3><p>我们安装前端编辑工具的目的是让我们在写的时候更一目了然、更方便。</p><ol><li>Visual Studio Code（LaTeX Workshop插件）<ul><li>优点：<ul><li>程序员必备软件，良好扩展，安装简单</li></ul></li><li>缺点：<ul><li>对新手和非程序员不友好，熟练使用比较复杂</li></ul></li></ul></li><li>LaTeX Workshop<ul><li>优点：<ul><li>专业TeX编写软件</li></ul></li><li>缺点：<ul><li>界面有点丑</li></ul></li></ul></li><li>Vim<ul><li>优点：<ul><li>大神神器，无所不能</li></ul></li><li>缺点：<ul><li>学习门槛巨大，只用键盘不用鼠标操作</li><li>年代久远已经过时</li></ul></li></ul></li></ol><h1 id="LaTeX安装"><a href="#LaTeX安装" class="headerlink" title="LaTeX安装"></a>LaTeX安装</h1><p>很显然要安装两个东西，一个前端，一个后端。前端和后端各自挑一个，可以自由组合。</p><div class="note info flat"><p>本教程使用Tex Live+Visual Studio Code(LaTeX Workshop插件)组合，如果你不想参考此项，可以跳过LaTeX安装的这一章。</p></div><div class="note info danger flat"><p>如果你Windows系统的用户名包含中文字符，则安装TeX Live极有可能失败！！！此时更推荐安装别的LaTeX实现版本！</p></div><h2 id="TeX-Live安装"><a href="#TeX-Live安装" class="headerlink" title="TeX Live安装"></a>TeX Live安装</h2><ol><li>打开<a href="https://mirrors.tuna.tsinghua.edu.cn/CTAN/systems/texlive/Images/">清华镜像源TeX Live镜像文件网站</a>下载iso文件<br><img src="../../../img/posts/LatexInstall/1.png" alt=""><br>不推荐官网下载是因为：LaTeX需要各种各样的宏包，可能安装程序在网上搜寻宏包的时候下载速度很不稳定，所以除了在<a href="https://www.tug.org/texlive/">官方网站</a>下载外，我更推荐在镜像源下载完整的镜像文件，这时就不用再依靠网络下载宏包了，而是本地安装。</li><li>点开install-tl-windows.exe安装程序（如果下载的是iso镜像文件，则先打开iso文件再去找对应的exe文件），点击左下角Advance.<br><img src="../../../img/posts/LatexInstall/2.png" alt=""></li><li>修改配置然后安装，可以把修改路径改到D盘之类的。<br><img src="../../../img/posts/LatexInstall/3.png" alt=""></li><li>等待安装完成，右下角的关闭按钮会亮起，点击关闭就行。安装用时可能需要几十分钟，当看到“欢迎进入TeX Live的世界”时就安装完成了。</li></ol><h2 id="TeX-Live验证"><a href="#TeX-Live验证" class="headerlink" title="TeX Live验证"></a>TeX Live验证</h2><p>安装完成TeX Live后需要验证是否安装成功。</p><ol><li>命令行输入<code>latex -v</code>执行。可以看到latex版本。</li><li>命令行输入<code>xelatex -v</code>执行，可以看到xelatex版本。</li><li>命令行输入<code>pdflatex -v</code>执行，可以看到pdflatex版本。</li></ol><p>若三个命令都能正常执行，则安装成功。</p><h2 id="Visual-Studio-Code-LaTeX-Workshop插件"><a href="#Visual-Studio-Code-LaTeX-Workshop插件" class="headerlink" title="Visual Studio Code(LaTeX Workshop插件)"></a>Visual Studio Code(LaTeX Workshop插件)</h2><ol><li>安装<a href="https://code.visualstudio.com/">Visual Studio Code</a>，应该没有程序员不会装VSCode吧、、、</li><li>插件栏搜索LaTeX Workshop，点击Install就能装好了。</li><li>按<kbd>F1</kbd>输入<code>Preferences: Open User Settings(JSON)</code>找到对应项点击，则打开了VSCode的设置文件。在该文件的花括号里粘贴以下内容：<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="attr">&quot;latex-workshop.latex.tools&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;pdflatex&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;pdflatex&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="string">&quot;-synctex=1&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="string">&quot;-interaction=nonstopmode&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="string">&quot;-file-line-error&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="string">&quot;%DOCFILE%&quot;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;xelatex&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;xelatex&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="string">&quot;-synctex=1&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="string">&quot;-interaction=nonstopmode&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="string">&quot;-file-line-error&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="string">&quot;%DOCFILE%&quot;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;bibtex&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;bibtex&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="string">&quot;%DOCFILE%&quot;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;latex-workshop.latex.recipes&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;xelatex&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="string">&quot;xelatex&quot;</span></span><br><span class="line">        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;pdflatex&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="string">&quot;pdflatex&quot;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;xe-&gt;bib-&gt;xe-&gt;xe&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="string">&quot;xelatex&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="string">&quot;bibtex&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="string">&quot;xelatex&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="string">&quot;xelatex&quot;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;pdf-&gt;bib-&gt;pdf-&gt;pdf&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="string">&quot;pdflatex&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="string">&quot;bibtex&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="string">&quot;pdflatex&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="string">&quot;pdflatex&quot;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;latex-workshop.latex.clean.fileTypes&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="string">&quot;*.aux&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;*.bbl&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;*.blg&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;*.idx&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;*.ind&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;*.lof&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;*.lot&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;*.out&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;*.toc&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;*.acn&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;*.acr&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;*.alg&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;*.glg&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;*.glo&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;*.gls&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;*.ist&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;*.fls&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;*.log&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;*.fdb_latexmk&quot;</span></span><br><span class="line"><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="comment">//tex文件浏览器，可选项为&quot;none&quot; &quot;browser&quot; &quot;tab&quot; &quot;external&quot;</span></span><br><span class="line"><span class="attr">&quot;latex-workshop.view.pdf.viewer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;tab&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="comment">//自动编译tex文件</span></span><br><span class="line"><span class="attr">&quot;latex-workshop.latex.autoBuild.run&quot;</span><span class="punctuation">:</span> <span class="string">&quot;onFileChange&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="comment">//显示内容菜单：（1）编译文件；（2）定位游标</span></span><br><span class="line"><span class="attr">&quot;latex-workshop.showContextMenu&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line"><span class="comment">//显示错误</span></span><br><span class="line"><span class="attr">&quot;latex-workshop.message.error.show&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line"><span class="comment">//显示警告</span></span><br><span class="line"><span class="attr">&quot;latex-workshop.message.warning.show&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line"><span class="comment">//从使用的包中自动补全命令和环境</span></span><br><span class="line"><span class="attr">&quot;latex-workshop.intellisense.package.enabled&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line"><span class="comment">//设置为never，为不清除辅助文件</span></span><br><span class="line"><span class="attr">&quot;latex-workshop.latex.autoClean.run&quot;</span><span class="punctuation">:</span> <span class="string">&quot;never&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="comment">//设置vscode编译tex文档时的默认编译链</span></span><br><span class="line"><span class="attr">&quot;latex-workshop.latex.recipe.default&quot;</span><span class="punctuation">:</span> <span class="string">&quot;lastUsed&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="comment">// 用于反向同步的内部查看器的键绑定。ctrl/cmd +点击(默认)或双击</span></span><br><span class="line"><span class="attr">&quot;latex-workshop.view.pdf.internal.synctex.keybinding&quot;</span><span class="punctuation">:</span> <span class="string">&quot;double-click&quot;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure></li></ol><p>请注意不要把花括号<code>&#123;</code>和<code>&#125;</code>给删了。</p><h2 id="Visual-Studio-Code-LaTeX-Workshop插件-验证"><a href="#Visual-Studio-Code-LaTeX-Workshop插件-验证" class="headerlink" title="Visual Studio Code(LaTeX Workshop插件)验证"></a>Visual Studio Code(LaTeX Workshop插件)验证</h2><p>最后要验证是否各项功能都能正常运行，编写或者复制简单的LaTeX模板文件，然后如下图点击开始生成pdf，若成功即可。</p><p><img src="../../../img/posts/LatexInstall/4.png" alt=""></p><p>至此，LaTeX的全部安装工作完成。</p>]]></content>
    
    
    <summary type="html">LaTeX的介绍、安装和基本使用</summary>
    
    
    
    <category term="一文读懂系列" scheme="https://shuqian8421.github.io/categories/%E4%B8%80%E6%96%87%E8%AF%BB%E6%87%82%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="LaTeX" scheme="https://shuqian8421.github.io/tags/LaTeX/"/>
    
  </entry>
  
  <entry>
    <title>博客优化记录</title>
    <link href="https://shuqian8421.github.io/posts/10713/"/>
    <id>https://shuqian8421.github.io/posts/10713/</id>
    <published>2024-07-27T16:00:00.000Z</published>
    <updated>2025-02-12T10:38:08.580Z</updated>
    
    <content type="html"><![CDATA[<div class="tabs" id="head"><ul class="nav-tabs no-default"><button type="button" class="tab " data-href="head-1">免责声明</button><button type="button" class="tab " data-href="head-2">动机</button></ul><div class="tab-contents"><div class="tab-item-content" id="head-1"><div class="note warning flat"><p>此文仅记录本博客参考的教程，不会对博客的配置、魔改问题做额外回复，权当一个本博客升级记录帖。<br>若参考本文而导致的任何问题，本人概不负责。</p></div></div><div class="tab-item-content" id="head-2"><p>从建站、修改配置到魔改，都需要记录一下用了哪些教程。如果后续魔改炸了的话还可以回溯。可惜我现在不太想对博客魔改本身做太多功夫，所以只记录参考过的教程吧。</p></div></div><div class="tab-to-top"><button type="button" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div><h2 id="建站"><a href="#建站" class="headerlink" title="建站"></a>建站</h2><h3 id="Hexo文档"><a href="#Hexo文档" class="headerlink" title="Hexo文档"></a>Hexo文档</h3><div class="tag link"><a class="link-card" title="Hexo概述" href="https://hexo.io/zh-cn/docs/"><div class="left"><img src="https://avatars.githubusercontent.com/u/6375567"/></div><div class="right"><p class="text">Hexo概述</p><p class="url">https://hexo.io/zh-cn/docs/</p></div></a></div><div class="tag link"><a class="link-card" title="Hexo建站" href="https://hexo.io/zh-cn/docs/setup"><div class="left"><img src="https://avatars.githubusercontent.com/u/6375567"/></div><div class="right"><p class="text">Hexo建站</p><p class="url">https://hexo.io/zh-cn/docs/setup</p></div></a></div><div class="tag link"><a class="link-card" title="Hexo配置" href="https://hexo.io/zh-cn/docs/configuration"><div class="left"><img src="https://avatars.githubusercontent.com/u/6375567"/></div><div class="right"><p class="text">Hexo配置</p><p class="url">https://hexo.io/zh-cn/docs/configuration</p></div></a></div><div class="tag link"><a class="link-card" title="Hexo指令" href="https://hexo.io/zh-cn/docs/commands"><div class="left"><img src="https://avatars.githubusercontent.com/u/6375567"/></div><div class="right"><p class="text">Hexo指令</p><p class="url">https://hexo.io/zh-cn/docs/commands</p></div></a></div><h3 id="Butterfly主题配置"><a href="#Butterfly主题配置" class="headerlink" title="Butterfly主题配置"></a>Butterfly主题配置</h3><div class="tag link"><a class="link-card" title="Butterfly 安装文档(一) 快速开始" href="https://butterfly.js.org/posts/21cfbf15/"><div class="left"><img src="https://avatars.githubusercontent.com/u/6375567"/></div><div class="right"><p class="text">Butterfly 安装文档(一) 快速开始</p><p class="url">https://butterfly.js.org/posts/21cfbf15/</p></div></a></div><div class="tag link"><a class="link-card" title="Butterfly 安装文档(二) 主题页面" href="https://butterfly.js.org/posts/dc584b87/"><div class="left"><img src="https://avatars.githubusercontent.com/u/6375567"/></div><div class="right"><p class="text">Butterfly 安装文档(二) 主题页面</p><p class="url">https://butterfly.js.org/posts/dc584b87/</p></div></a></div><div class="tag link"><a class="link-card" title="Butterfly 安装文档(三) 主题配置-1" href="https://butterfly.js.org/posts/4aa8abbe/"><div class="left"><img src="https://avatars.githubusercontent.com/u/6375567"/></div><div class="right"><p class="text">Butterfly 安装文档(三) 主题配置-1</p><p class="url">https://butterfly.js.org/posts/4aa8abbe/</p></div></a></div><div class="tag link"><a class="link-card" title="Butterfly 安装文档(四) 主题配置-2" href="https://butterfly.js.org/posts/ceeb73f/"><div class="left"><img src="https://avatars.githubusercontent.com/u/6375567"/></div><div class="right"><p class="text">Butterfly 安装文档(四) 主题配置-2</p><p class="url">https://butterfly.js.org/posts/ceeb73f/</p></div></a></div><div class="tag link"><a class="link-card" title="Butterfly 安装文档(六) 进阶教程" href="https://butterfly.js.org/posts/4073eda/"><div class="left"><img src="https://avatars.githubusercontent.com/u/6375567"/></div><div class="right"><p class="text">Butterfly 安装文档(六) 进阶教程</p><p class="url">https://butterfly.js.org/posts/4073eda/</p></div></a></div><h3 id="主题美化"><a href="#主题美化" class="headerlink" title="主题美化"></a>主题美化</h3><div class="tag link"><a class="link-card" title="Butterfly主题美化日记" href="https://akilar.top/posts/f99b208/"><div class="left"><img src="https://npm.elemecdn.com/akilar-candyassets/image/siteicon/favicon.ico"/></div><div class="right"><p class="text">Butterfly主题美化日记</p><p class="url">https://akilar.top/posts/f99b208/</p></div></a></div><div class="tag link"><a class="link-card" title="糖果屋微调合集" href="https://akilar.top/posts/23fdf850/"><div class="left"><img src="https://npm.elemecdn.com/akilar-candyassets/image/siteicon/favicon.ico"/></div><div class="right"><p class="text">糖果屋微调合集</p><p class="url">https://akilar.top/posts/23fdf850/</p></div></a></div>]]></content>
    
    
    <summary type="html">拥有博客优化记录可以在重大升级和更改出错时回溯，不至于把博客玩崩！</summary>
    
    
    
    <category term="博客维护" scheme="https://shuqian8421.github.io/categories/%E5%8D%9A%E5%AE%A2%E7%BB%B4%E6%8A%A4/"/>
    
    
    <category term="Hexo" scheme="https://shuqian8421.github.io/tags/Hexo/"/>
    
    <category term="Butterfly" scheme="https://shuqian8421.github.io/tags/Butterfly/"/>
    
    <category term="博客" scheme="https://shuqian8421.github.io/tags/%E5%8D%9A%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>一文读懂如何进行密码管理（本教程使用Keepass）</title>
    <link href="https://shuqian8421.github.io/posts/4231/"/>
    <id>https://shuqian8421.github.io/posts/4231/</id>
    <published>2024-07-27T16:00:00.000Z</published>
    <updated>2025-02-12T10:38:08.580Z</updated>
    
    <content type="html"><![CDATA[<div class="tabs" id="head"><ul class="nav-tabs no-default"><button type="button" class="tab " data-href="head-1">动机</button><button type="button" class="tab " data-href="head-2">免责声明</button><button type="button" class="tab " data-href="head-3">参考</button></ul><div class="tab-contents"><div class="tab-item-content" id="head-1"><p>学习通数据库泄露和QQ号被盗的事件影响颇大，这才又让我认识到密码管理的重要性。个人之前一直用的是Keepass管理自己的密码，不过也只用了基本功能，这次正好可以把这个软件深入研究一下。<br>同时这是一文读懂系列的第一个文章，希望以后一文读懂系列能给读者提供一站式的、清晰简洁的讲解教程。</p></div><div class="tab-item-content" id="head-2"><div class="note danger flat"><p>本文所使用的都是开源密码管理工具，虽说安全性强、使用人数多，但我仍没法100%保证软件本身的安全性。因此，我建议各位读者在参考本教程进行密码管理时务必抱着怀疑的态度进行学习，参考该教程而导致的安全问题本人概不负责。</p></div></div><div class="tab-item-content" id="head-3"><div class="tag link"><a class="link-card" title="密码学和网络安全知识 1： 密码、口令与密钥" href="https://zhuanlan.zhihu.com/p/463628812"><div class="left"><img src="/img/website_favicon.png"/></div><div class="right"><p class="text">密码学和网络安全知识 1： 密码、口令与密钥</p><p class="url">https://zhuanlan.zhihu.com/p/463628812</p></div></a></div><div class="tag link"><a class="link-card" title="Keepass官方网站" href="https://keepass.info/"><div class="left"><img src="/img/website_favicon.png"/></div><div class="right"><p class="text">Keepass官方网站</p><p class="url">https://keepass.info/</p></div></a></div><div class="tag link"><a class="link-card" title="一劳永逸：KeePass全网最详使用指南" href="https://zhuanlan.zhihu.com/p/39645975"><div class="left"><img src="/img/website_favicon.png"/></div><div class="right"><p class="text">一劳永逸：KeePass全网最详使用指南</p><p class="url">https://zhuanlan.zhihu.com/p/39645975</p></div></a></div><div class="tag link"><a class="link-card" title="keepass混淆输入" href="https://www.csdn.net/tags/NtTaggxsNDIwMDgtYmxvZwO0O0OO0O0O.html"><div class="left"><img src="/img/website_favicon.png"/></div><div class="right"><p class="text">keepass混淆输入</p><p class="url">https://www.csdn.net/tags/NtTaggxsNDIwMDgtYmxvZwO0O0OO0O0O.html</p></div></a></div><div class="tag link"><a class="link-card" title="5千字长文：KeePass完全入门指南（附已经配置好的版本）" href="https://blog.csdn.net/axutongxue/article/details/118696485"><div class="left"><img src="/img/website_favicon.png"/></div><div class="right"><p class="text">5千字长文：KeePass完全入门指南（附已经配置好的版本）</p><p class="url">https://blog.csdn.net/axutongxue/article/details/118696485</p></div></a></div><div class="tag link"><a class="link-card" title="密码管理程序Keepass教程" href="https://www.jianshu.com/p/4ff8b6930372"><div class="left"><img src="/img/website_favicon.png"/></div><div class="right"><p class="text">密码管理程序Keepass教程</p><p class="url">https://www.jianshu.com/p/4ff8b6930372</p></div></a></div></div></div><div class="tab-to-top"><button type="button" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div><h1 id="密码基础"><a href="#密码基础" class="headerlink" title="密码基础"></a>密码基础</h1><h2 id="什么是密码"><a href="#什么是密码" class="headerlink" title="什么是密码"></a>什么是密码</h2><p>首先要明确的是，密码学里的“密码”和大众眼中的“密码”是两个概念。这里讲讲口令、密码和密钥。</p><p>口令：password，用于验证鉴别。在大部分互联网应用中会对不同的用户设置不同的身份和口令。如果你告知应用自己的身份，然后再通过告诉应用口令，那就能证明自己的身份。很明显，这里的口令就是我们平常生活中说的“密码”。</p><p>口令有一个基本特征：<strong>由可书写可读的字母、数字、符号、词组成，便于头脑记忆。</strong></p><p>密码：在密码学里指密码算法，我们可以通俗理解成把可以被大家理解的信息转化成大家不理解的杂乱无章的字符之类的信息。密码算法有许多种，这里就不展开了。</p><p>密钥：密码算法可以传入参数，密钥就是这些参数。对于同一种密码算法，传入的密钥参数不同，对应转化的结果也就不同。</p><p>但是，这篇文章是面向大众的科普向文章，博主本人也没密码学相关知识背景，所以我们对这些概念不必过分深究。我们就采用大众理解的概念来理解密码。</p><div class="note info flat"><p>在此段以后的整篇文章中，我们提到的“密码”，若非特别说明，一律指大众理解的密码，也就是登陆时填的那个口令password。</p></div><h2 id="密码设置的注意事项"><a href="#密码设置的注意事项" class="headerlink" title="密码设置的注意事项"></a>密码设置的注意事项</h2><p>密码在使用方便前必须考虑安全性。只有在足够安全的前提下你才能开始考虑怎么方便使用。</p><p><strong>以下是推荐做的事情</strong></p><div class="note info flat"><p>有一些方法挺不错，你可以采用。</p><ol><li>有些人采用分级密码管理方法，比如设置三级密码，第一级密码非常重要，用于管理钱财的软件等APP，所以这个密码很复杂、很关键、很保密，只作为固定几个地方的密码；第二级密码用于官方认证的网站，不涉及金钱交易，比较放心，所以在密码的复杂性、保密性上可以稍微妥协，可以有比较多的网站使用这个密码；第三级密码用于野鸡网站，听都没听过的那种，这时设置的密码就可以很随便了。当然，你也可以用五级密码、七级密码或更多级，前提是你要记得住这些密码。</li><li>大小写结合加数字再加特殊符号更安全哦，而且越长越好。但问题是，对很多人来说，密码越复杂越长，就越倾向于多个地方用同一密码，因为懒得记。既然倾向于多个地方同一个密码，结果风险反而更高了。</li><li>假设有密码<code>123456</code>，那把QQ密码设成<code>QQ123456</code>，Steam密码设成<code>Steam123456</code>。不过这也不太安全。如果你两个密码泄露了，那剩下的不难猜出规律。</li><li>记在小本本上，不过前提是你要保证把小本本放好位置别丢了。 </li><li>一个有名的程序员肯汤普森，他的某个密码散列后的字符串是<code>ZghOT0eRm4U9s</code>，快40年后才被暴力破解，明文是<code>p/q2-q4!</code>，这个明文意思是国际象棋里的一个常见的开局走法：皇后前面的兵向前移动 2 个方格。同样的道理，以下这密码可能给你思路：飞流直下三千尺，疑是银河落九天。密码就是flzx3000c,YSYHL9T.</li><li>你可能不信，但手机验证码是普通人能接触到的最安全的方法了。</li><li>密码管理软件可以生成随机密码，坏处是你根本难以记住，好处是密码管理软件能管理你的密码。</li><li>有一种免费的密码管理软件，可以从庞大的数据中快速找到特定的密码，完全不存在数据泄露的可能性，我们一般称这个软件为大脑。</li></ol></div><p><strong>以下是你禁止做的事情</strong></p><div class="note danger flat"><p><strong>你不能这么做！！！</strong></p><ol><li>所有网站都用同一个密码</li><li>把密码告诉妈妈，跟她说不要告诉别人</li><li>把密码记在一个txt文件里面，然后把名字改成meiyoumima.jpg</li><li>在一个photoshop文件里面建一个新图层，把账号密码写上去，背景和字体设成白色，想看密码的时候开ps文件看。</li><li>密码设成123456</li><li>浏览器问你要不要保存输的密码，你选了要</li><li>你住在北京，你叫小明，你的生日是2月29日，你的密码设成xiaomingbeijing0229</li><li>听别人说MD5是加密算法，然后就糊里糊涂用简单的口令进行MD5转换后当密码</li><li>支持国产！把密码交给百度管理吧！</li></ol></div><h1 id="如何选择密码管理软件"><a href="#如何选择密码管理软件" class="headerlink" title="如何选择密码管理软件"></a>如何选择密码管理软件</h1><p>这时你大概已经明白什么样的密码是好密码，什么样的密码是坏密码了。很多人都在用各种各样的密码管理软件，我也推荐你选择一个。</p><p>在选择密码管理软件之前，你要知道<emp>你自己</emp>对密码管理软件有什么样的要求，这会导致你更喜欢某个或某些管理密码软件。<br><div class="note info flat"><p>先问问自己：</p><ol><li>想选择的加密算法是什么？这个加密算法安全吗？你可能不知道加密算法安不安全，不过至少不要让密码是明文存储的。至于哪种加密算法更安全，各种专业人士自然有各自的见解。</li><li>代码开源吗？可能我们不会拿开源代码去魔改，但是既然它开源那就比较良心，不用担心之后收费之类的问题，开发者夹带私货的概率也大大降低。不过注意，开源不意味着完全安全，只是出问题的概率会低那么一点。</li><li>是离线的软件还是在线的网站？通常来说，我们倾向于认为在线才能用的密码软件或密码网站是有风险的，我们更愿意使用离线的软件来管理密码（除非特殊情况）。</li><li>免费吗？秉持着白嫖不花一分钱的信念，大家确实更喜欢不交钱的东西。不过通常来说付费软件在某些方面可能更好。这个问题见仁见智。</li><li>是否有好用的扩展？在需要密码的时候还要再开软件看一看是很麻烦的行为，所以很多密码管理软件通过扩展达到自动填充的简便效果。你当然可能用浏览器保存密码，不过浏览器自动填充密码和密码管理软件自动填充密码是不一样的，后者更安全。</li><li>麻烦吗？很多小白可能对这些技术不太感兴趣，所以更推荐他们用一些一键安装就完事的软件。不过如果你能找到这篇文章并读到这里，我相信你应该是有一定基础的，所以我们可能不太管上手的难易程度，我们更关心把所有东西都设置好后管理密码方不方便、安不安全。</li><li>用的人多吗？在选择密码管理软件这件事上可不要自命清高，千万不要选择一些冷门的软件。越多人使用，越多人审查代码安全性，越多的扩展，越舒心的体验。</li></ol></div></p><p>想好后，下面这张图可以带你了解目前市面上各大密码管理软件优缺点。</p><p><img src="../../../../img/posts/PasswordManagement/1.jfif" alt="不同密码管理器信息"></p><p>相信不同的读者此时心里已经有了不同的选择。<br>我选择了Keepass。若你和我选择相同，请继续阅读。若你想找其他的密码管理软件，现在就百度/Google吧！</p><p>那么废话不多说，开始我们的Keepass的探索之旅吧！</p><h1 id="Keepass密码管理软件"><a href="#Keepass密码管理软件" class="headerlink" title="Keepass密码管理软件"></a>Keepass密码管理软件</h1><p>最终，来到了我们这篇文章的重头戏。接下来我们会介绍在Windows操作系统、Android移动端设备上如何优雅地使用Keepass来管理密码和使用密码。小提示，普通程序员看懂这篇文章应该没有难度，如果你是电脑小白，可能看懂的话会比较吃力哦！</p><h2 id="Keepass介绍"><a href="#Keepass介绍" class="headerlink" title="Keepass介绍"></a>Keepass介绍</h2><p>或许你可以看看<a href="https://keepass.info/">Keepass官网</a>是如何介绍自己的。<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Why KeePass?</span><br><span class="line">Today, you have to remember many passwords. You need a password for a lot of websites, your e-mail account, your webserver, network logins, etc. The list is endless. Also, you should use a different password for each account, because if you would use only one password everywhere and someone gets this password, you would have a problem: the thief would have access to all of your accounts.</span><br><span class="line">KeePass is a free open source password manager, which helps you to manage your passwords in a secure way. You can store all your passwords in one database, which is locked with a master key. So you only have to remember one single master key to unlock the whole database. Database files are encrypted using the best and most secure encryption algorithms currently known (AES-256, ChaCha20 and Twofish). For more information, see the features page.</span><br><span class="line"></span><br><span class="line">Is it really free?</span><br><span class="line">Yes, KeePass is really free, and more than that: it is open source (OSI certified). You can have a look at its full source code and check whether the security features are implemented correctly.</span><br></pre></td></tr></table></figure></p><p>看得出来，Keepass有以下特点：</p><ul><li>开源免费</li><li>可以不用手输密码</li><li>作为开源软件当然有大量第三方插件支持</li><li>离线存储、高水平加密算法</li><li>全平台通用</li></ul><p>这篇文章只记录了重要的操作步骤，Keepass还有很多功能，读者可以自行到官网上查阅文档。</p><h2 id="Keepass在Windows端如何使用"><a href="#Keepass在Windows端如何使用" class="headerlink" title="Keepass在Windows端如何使用"></a>Keepass在Windows端如何使用</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><ol><li>在<a href="https://keepass.info/download.html">Keepass官网下载页</a>里找不同版本release下载。你可以看到有安装程序.exe格式和压缩包.zip格式。.exe格式会让Keepass像正常程序装进你的系统中；.zip格式则都在文件夹内部存储数据，你可以把文件夹搬运到不同设备上，很方便。二选一即可。</li><li>我选择安装程序，运行setup程序。（安装时默认英文）</li><li>第一步Select Setup Language不选，直接点<kbd>OK</kbd>，因为默认不提供中文选项。</li><li>选择安装路径，除非你是大佬，不然别装C盘。</li><li>一路点<kbd>OK</kbd>或<kbd>Next</kbd>。</li></ol><p>至此安装完成，第一次打开会提示“是否自动更新？”要不要自动更新取决于你自己。</p><h3 id="汉化"><a href="#汉化" class="headerlink" title="汉化"></a>汉化</h3><p>怎么设置成中文版呢？</p><ol><li>打开Keepass，依次点击<kbd>View</kbd>-&gt;<kbd>Change Language</kbd>可以选择语言。第一次打开肯定只有英文，点击<kbd>Get More</kbd>能开官方网站，然后下载汉化语言包。</li><li>打开的官方网站中有各种语言，选择<kbd>Chinese, Simp.</kbd>条目对应的Downloads栏，有1.40+和2.51+两个版本，选2.51+的那个。下载后解压得到一个LNGX格式的文件。</li><li>回到原来Select Language界面，刚刚点击的是Get More，现在点击右边的<kbd>Open Folder</kbd>，把刚刚下载的LNGX文件放进我们打开的文件夹里面去。</li><li>再次回到Keepass界面点击<kbd>View</kbd>然后点<kbd>Change Language</kbd>，就能看到中文选项。点击后会要求重启Keepass，选<kbd>是</kbd>进行重启。</li></ol><h3 id="基本使用与第一次配置注意事项"><a href="#基本使用与第一次配置注意事项" class="headerlink" title="基本使用与第一次配置注意事项"></a>基本使用与第一次配置注意事项</h3><ol><li>创建数据库<ul><li>开始行动前，我们先理一理需要创建的东西。Keepass会把你的密码放进一个kdbx文件的数据库里面的。在创建数据库时Keepass提供了3种可任意组合的加密方式：【管理密码】【密钥文件/提供器】和【Windows 用户账户】，至少选一种加密方式，也就是说一共可以组合出<script type="math/tex">C_3^3 +C_3^2 + C_3^1 = 7</script>种不同的加密方式。密钥正如之前我们提到的，是一个文件，也要创建一个新的，如果密码被别人知道了但密钥文件不在别人手上，那么也打不开这个数据库，提高了安全性。如果你是小白，我们推荐【管理密码】+【密钥文件/提供器】加密方式，也就是接下来的内容。</li><li>在Keepass主界面，点击<kbd>文件</kbd>-&gt;<kbd>新建</kbd>，出现新提示窗口，点击<kbd>OK</kbd>，然后选择数据库存放的路径并点<kbd>确定</kbd>。</li><li>在“创建组合管理密码”界面里，把“显示高级选项”点开。这个界面里最上面输入的是主密码，你可以理解成“管理密码的密码”，看得出来非常重要，建议每隔半年就要换一次，另外记得一定要深深地把主密码刻在脑海里面。接下来是设置密钥，你当然可以不设，但我们强力推荐你设置一个密钥文件：【密钥文件/提供器】的选项点开，然后点<kbd>创建</kbd>，然后在“创建密钥文件”界面点<kbd>确定</kbd>。新打开的“收集熵”界面，左边随便按着鼠标拖一拖就好了；右边输入框让你随便输字符，你不用记住你敲了什么键，你输的这些字符是用来当作种子用于高强度加密的，只要乱敲就行<psw>（所以可在这里试看看脸滚键盘）</psw>。接下来点<kbd>确定</kbd>，接着就是要将生成的密钥文件保存在你想保存的路径里面。为了防止密钥文件丢失，你可以做备份。黑客拿到密钥文件时没法读取你任何信息的。现在已经设好了主密码，设置好了密钥文件，就可以点<kbd>确定</kbd>了。</li><li>记住，主密码、密钥文件、数据库不要放在同一个地方，不然你白忙活了！黑客看到数据库的同时发现你把密钥文件放在同一个目录下，那你这密钥设和没设没啥差别。主密码推荐写在一个小纸张上，或如下文所说打印应急表单也行，当然如果你非要记脑子里我也不反对。</li><li>通常来说密钥文件的路径我们是让Keepass自动记住的，也就是说你不移动密钥文件的话我们每次进Keepass只要输主密码就可以。但如果你电脑要借出、或这是公用电脑，那不要让Keepass记得你的密钥路径，你可以在主界面<kbd>工具</kbd>→<kbd>选项</kbd>→<kbd>高级</kbd>的“高级”里关闭<kbd>记住密钥源（密钥文件路径、提供者名称等）</kbd>选项。这个选项默认是选中的。</li><li>接下来进入“配置新数据库”界面。“常规”这一页按需求填写。“安全”这一页，注意【迭代次数】，次数越高数据库越难被暴力破解，但每次打开数据库和保存记录的耗时也越长。默认值为60000。我把它设置为5000000，在我的电脑内大概0.1秒的时间。你也可以点<kbd>1秒延迟</kbd>按钮，对应的次数就是你花1秒成功的大概次数。在“高级”一页，有“建议更换管理密钥天数”，也就是你主密码设置成功过了多少天后会为了安全建议你换另一个主密码，你不换的话就会每次打开Keepass都开弹窗烦你。“强制更换管理密钥天数”就是非让你换主密码不可了。这两个按需求配置，我比较懒所以我都没勾选哈哈。</li><li>创建数据库最后一步就是应急表单了。这个是为了防止哪天你可能就把主密码忘了。推荐打印一份放在你家里或隐蔽的安全的地方。你可能一年的时间都不会碰，但情急时那张纸就是救命稻草。别想着能找回密码，不可能找回的，你忘了那就再也打不开了。所以慎重！！！一定要记得主密码！而且密钥文件放的位置也要记得！<div class="note danger flat"><p>保存好应急表单！主密码一旦忘记无法找回！</p></div></li></ul></li><li>Keepass安全设置<br>Keepass也可能是很不安全的，这并不是因为Keepass设计的不好，而是因为如果你开了这个软件后就跑开了让别人看到你的密码，那只能怪你自己喽。这只是个例子，接下来就教你怎么设置让你能更安全地使用Keepass。<ul><li>密码用了之后就要从剪贴板里清除，电脑长时间没动作时要让Keepass自动锁定。你可以在<kbd>工具</kbd>→<kbd>选项</kbd>→<kbd>安全</kbd>里设置相关选项。<kbd>全局空闲如下时间后锁定主窗口（秒）</kbd><strong>强烈建议</strong>打开，几秒看你需求调；<kbd>剪贴板自动清空时间（秒，主记录列表）</kbd><strong>强烈建议</strong>打开，几秒看你需求调，如果有按下文设置自动输入的话可以调短一点，比如10秒左右之类的。另外常规里的<kbd>锁定Keepass--当锁定Windows或切换用户时</kbd>和<kbd>锁定Keepass--当系统挂起时</kbd>和<kbd>锁定Keepass--当远程控制模式改变时</kbd>这三个选项建议勾起来。</li><li>在<kbd>工具</kbd>→<kbd>选项</kbd>→<kbd>高级</kbd>里，把【启动和退出】里的<kbd>退出和锁定数据库时自动保存</kbd>勾上。同样是在<kbd>高级</kbd>这个页面，把【文件输入/输出连接】里的<kbd>写入数据库时使用文件交换处理（先写入临时文件再替换原文件，以防意外）</kbd>取消勾选。</li><li>防熊孩子和别有用心的人：打开<kbd>工具</kbd>→<kbd>选项</kbd>→<kbd>策略</kbd>，将以下4个选项进行<strong>关闭</strong>：<kbd>导出</kbd>、<kbd>导出-不核对密码</kbd>、<kbd>打印</kbd>、<kbd>打印-不核对密码</kbd>。</li><li>原则上，<strong>严禁</strong>Keepass联网。</li><li>一定要养成随手锁电脑（<kbd>win</kbd>+<kbd>L</kbd>）的习惯！</li></ul></li><li>基本简单操作：如何设置密码、使用密码<br>这应该不用我说了吧</li></ol><h3 id="进阶设置"><a href="#进阶设置" class="headerlink" title="进阶设置"></a>进阶设置</h3><ol><li>为使你的主密码更安全，请在keepass的<kbd>工具</kbd>→<kbd>选项</kbd>→<kbd>安全</kbd>的“高级”中勾选<kbd>在安全桌面输入管理密码</kbd>，因为几乎没有键盘记录软件能在安全桌面工作。</li><li><p>自动输入</p><ul><li>这一步要注意，如果目标应用程序要求管理员权限运行，那么keepass也要用管理员权限运行才能使用自动输入。所以你不妨马上试试右键Keepass图标然后点【以管理员身份运行】。自动输入全局热键默认为<kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>A</kbd>。两种方法使用自动输入：1. 点击输入框→按下自动输入全局热键。2. 点击输入框→切换到Keepass主界面→右键单击记录→<kbd>执行自动输入</kbd>。</li><li>自动输入的匹配规则：当按下自动输入全局热键时，keepass会根据当前活动窗口的标题在数据库中搜索相匹配的记录；如果一条记录的标题或网址包含在活动窗口标题内那么这条记录将被匹配。举个例子：在chrome浏览器中打开淘宝网，当前活动窗口的标题就是“淘宝网 - 淘！我喜欢 - Google Chrome”。那么问题来了：标题为“Google”的记录也会被匹配到，而且在chrome中打开的任何标签页的标题都会包含“Google Chrome”字段。</li><li>为防止误匹配，上述问题解决方法为：依次点击<kbd>工具</kbd>→<kbd>选项</kbd>→<kbd>高级</kbd>，勾选<kbd>总是显示全局自动输入记录选取对话框</kbd>。</li><li>自动输入的键入规则，默认规则为{USERNAME}{TAB}{PASSWORD}{ENTER}。也就是先输入用户名，tab换行，输密码，回车。但这只适用于英文，当我们使用中文输入法时可能失效，所以<strong>推荐使用</strong>以下规则：+{DELAY 100}{CLEARFIELD}{USERNAME}{TAB}{PASSWORD}{ENTER}。解释：按shift键，等100毫秒，清空输入框，输用户名，tab换行，输密码，回车。由于新建记录默认从群组继承输入规则，所以只需修改一次，一劳永逸。</li><li><p>综上，当你遵守以下要求时</p><ul><li>自动输密码前确保输入法是中文</li><li>想要自动输入的密码会在你执行这些配置后添加（也就是说在你配置之前就已经设好的密码没法用自动输入）</li></ul><p>那么你就可以这么配置来一次性保证以后你添加的密码能够使用自动输入：</p><ul><li>在Keepass主界面左侧栏右键你的密码数据库→<kbd>编辑群组</kbd>→<kbd>自动输入</kbd>，选择<kbd>替代默认规则为</kbd>，下面填写<code>+&#123;DELAY 100&#125;&#123;CLEARFIELD&#125;&#123;USERNAME&#125;&#123;TAB&#125;&#123;PASSWORD&#125;&#123;ENTER&#125;</code></li><li>我们在上面提到过的，依次点击<kbd>工具</kbd>→<kbd>选项</kbd>→<kbd>高级</kbd>，勾选<kbd>总是显示全局自动输入记录选取对话框</kbd>。</li><li>以后你想使用自动输入时，就是我们已经讲过的两种方法。1. 点击输入框→按下自动输入全局热键。2. 点击输入框→切换到Keepass主界面→右键单击记录→<kbd>执行自动输入</kbd>。</li></ul></li></ul></li><li>双通道自动混淆输入<ul><li>原理确实有点让人头大，我把文档贴在这儿吧  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">The Auto-Type feature of KeePass is very powerful: it sends simulated keypresses to other applications. This works with all Windows applications and for the target applications it&#x27;s not possible to distinguish between real keypresses and the ones simulated by Auto-Type. This at the same time is the main disadvantage of Auto-Type, because keyloggers can eavesdrop the simulated keys. That&#x27;s where Two-Channel Auto-Type Obfuscation (TCATO) comes into play.</span><br><span class="line"></span><br><span class="line">TCATO makes standard keyloggers useless. It uses the Windows clipboard to transfer parts of the auto-typed text into the target application. Keyloggers can see the Ctrl+V presses, but do not log the actual contents pasted from the clipboard.</span><br><span class="line"></span><br><span class="line">Clipboard spies don&#x27;t work either, because only parts of the sensitive information is transferred on this way.</span><br><span class="line"></span><br><span class="line">Anyway, it&#x27;s not perfectly secure (and unfortunately cannot be made by theory). None of the currently available keyloggers or clipboard spies can eavesdrop an obfuscated auto-type process, but it is theoretically possible to write a dedicated spy application that specializes on logging obfuscated auto-type.</span><br></pre></td></tr></table></figure>  简单来说，将要输入的字符分两部分，用模拟按键和复制粘贴两种方式混合输入，输入完成后再还原输入前的剪贴板内容。这样时为了防止单一的键盘记录软件或剪贴板监听软件窃取输入的完整字段。有些软件不支持这个功能，因此这个功能默认不启用。</li><li>如何使用双通道混淆输入：在添加记录时或编辑记录时，<kbd>自动输入</kbd>子界面有个<kbd>双通道自动输入混淆</kbd>，把它打开。</li></ul></li></ol><h3 id="插件设置"><a href="#插件设置" class="headerlink" title="插件设置"></a>插件设置</h3><p>如何进行插件安装？Keepass主界面点击<kbd>工具</kbd>-&gt;<kbd>插件管理器</kbd>-&gt;<kbd>打开文件夹</kbd>，然后把你想放的plgx文件放进去就行。然后重新打开Keepass。<br><div class="note warning flat"><p>警告！使用非官方的插件可能有风险！如果插件带来了安全问题，你可能无法承受后果！</p></div></p><h2 id="Keepass在Android端如何使用"><a href="#Keepass在Android端如何使用" class="headerlink" title="Keepass在Android端如何使用"></a>Keepass在Android端如何使用</h2><p>没想到吧！Keepass也能在安卓上使用！手机上使用Keepass会简单得多，我们推荐Keepass2Android这个神器！在<a href="https://keepass.info/download.html">Keepass官网下载页</a>里你就能看到Keepass2Android的下载链接！</p><h2 id="密码数据库文件"><a href="#密码数据库文件" class="headerlink" title="密码数据库文件"></a>密码数据库文件</h2><p>我们现在可能在多个平台都需要密码数据库文件。那么如何做到同步多端数据库文件呢？</p><ol><li>放在云盘。例如Onedrive等等。</li><li>在电脑更新，每隔一段时间就把文件备份到手机上。</li></ol>]]></content>
    
    
    <summary type="html">使用Keepass对自己的密码进行管理，保证自己账号的安全！</summary>
    
    
    
    <category term="一文读懂系列" scheme="https://shuqian8421.github.io/categories/%E4%B8%80%E6%96%87%E8%AF%BB%E6%87%82%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="Keepass" scheme="https://shuqian8421.github.io/tags/Keepass/"/>
    
    <category term="密码" scheme="https://shuqian8421.github.io/tags/%E5%AF%86%E7%A0%81/"/>
    
  </entry>
  
</feed>
